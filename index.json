[{"categories":null,"content":"Deployment is great There are so many things to talk about. Practically, just remember the following Tips: Use Readiness Probes for your application Control your rollouts with an Update Strategy appropriate for your application Use the – record option to leave a trail of your work for others ","date":"2023-03-16","objectID":"/k8s/deployment/:0:0","tags":["K8s","Course"],"title":"Deployment","uri":"/k8s/deployment/"},{"categories":null,"content":"Install eksctl and kubectl eksctl.io $ curl --silent --location \"https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\" | tar xz -C /tmp $ sudo mv /tmp/eksctl ~/.local/bin/ $ eksctl version 0.133.0 $ . \u003c(eksctl completion bash) Amazon EKS $ curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.25.6/2023-01-30/bin/linux/amd64/kubectl % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 42.9M 100 42.9M 0 0 2295k 0 0:00:19 0:00:19 --:--:-- 3581k $ mv kubectl ~/.local/bin/ $ chmod a+x ~/.local/bin/kubectl Create an EKS cluster $ eksctl get --profile dec --region us-east-1 cluster No clusters found $ eksctl create --profile dec --region us-east-1 cluster --name wp-cluster :10:58 [ℹ] eksctl version 0.133.0 :10:58 [ℹ] using region us-east-1 :10:59 [ℹ] setting availability zones to [us-east-1d us-east-1a] :10:59 [ℹ] subnets for us-east-1d - public:192.168.0.0/19 private:192.168.64.0/19 :10:59 [ℹ] subnets for us-east-1a - public:192.168.32.0/19 private:192.168.96.0/19 :10:59 [ℹ] nodegroup \"ng-c3af3c25\" will use \"\" [AmazonLinux2/1.24] :10:59 [ℹ] using Kubernetes version 1.24 :10:59 [ℹ] creating EKS cluster \"wp-cluster\" in \"us-east-1\" region with managed nodes :10:59 [ℹ] will create 2 separate CloudFormation stacks for cluster itself and the initial managed nodegroup :10:59 [ℹ] if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=us-east-1 --cluster=wp-cluster' :10:59 [ℹ] Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster \"wp-cluster\" in \"us-east-1\" :10:59 [ℹ] CloudWatch logging will not be enabled for cluster \"wp-cluster\" in \"us-east-1\" :10:59 [ℹ] you can enable it with 'eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=us-east-1 --cluster=wp-cluster' :10:59 [ℹ] 2 sequential tasks: { create cluster control plane \"wp-cluster\", 2 sequential sub-tasks: { wait for control plane to become ready, create managed nodegroup \"ng-c3af3c25\", } } :10:59 [ℹ] building cluster stack \"eksctl-wp-cluster-cluster\" :10:59 [ℹ] deploying stack \"eksctl-wp-cluster-cluster\" :11:29 [ℹ] waiting for CloudFormation stack \"eksctl-wp-cluster-cluster\" :27:05 [ℹ] building managed nodegroup stack \"eksctl-wp-cluster-nodegroup-ng-c3af3c25\" :27:05 [ℹ] deploying stack \"eksctl-wp-cluster-nodegroup-ng-c3af3c25\" :27:05 [ℹ] waiting for CloudFormation stack \"eksctl-wp-cluster-nodegroup-ng-c3af3c25\" :31:35 [ℹ] waiting for the control plane to become ready :31:36 [✔] saved kubeconfig as \"/home/vma/.kube/config\" :31:36 [ℹ] no tasks :31:36 [✔] all EKS cluster resources for \"wp-cluster\" have been created :31:36 [ℹ] nodegroup \"ng-c3af3c25\" has 2 node(s) :31:36 [ℹ] node \"ip-192-168-14-169.ec2.internal\" is ready :31:36 [ℹ] node \"ip-192-168-61-46.ec2.internal\" is ready :31:36 [ℹ] waiting for at least 2 node(s) to become ready in \"ng-c3af3c25\" :31:36 [ℹ] nodegroup \"ng-c3af3c25\" has 2 node(s) :31:36 [ℹ] node \"ip-192-168-14-169.ec2.internal\" is ready :31:36 [ℹ] node \"ip-192-168-61-46.ec2.internal\" is ready :31:39 [ℹ] kubectl command should work with \"/home/vma/.kube/config\", try 'kubectl get nodes' :31:39 [✔] EKS cluster \"wp-cluster\" in \"us-east-1\" region is ready $ aws cloudformation --profile dec list-stacks --query 'StackSummaries[].StackName' | grep eksctl \"eksctl-wp-cluster-nodegroup-ng-c3af3c25\", \"eksctl-wp-cluster-cluster\", $ kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE local51 kubernetes kubernetes-admin * vma@wp-cluster.us-east-1.eksctl.io wp-cluster.us-east-1.eksctl.io vma@wp-cluster.us-east-1.eksctl.io $ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-192-168-14-169.ec2.internal Ready \u003cnone\u003e 3m27s v1.24.10-eks-48e63af ip-192-168-61-46.ec2.internal Ready \u003cnone\u003e 3m26s v1.24.10-eks-48e63af Deploy an example wordpress app $ kubectl create secret generic mysql-pass --from-literal=password=mypassword secret/mysql-pass","date":"2023-03-15","objectID":"/k8s/eks_install/:0:0","tags":["AWS","K8s","Tips"],"title":"Eks_install","uri":"/k8s/eks_install/"},{"categories":null,"content":"Creat an example app with docker swarm Here is an app based on latest wordpress and mysql 5.7 docker image. $ cat \u003c\u003cEOF \u003e stack.yaml version: '3.1' services: db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: example MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: image: wordpress:latest ports: - \"8000:80\" environment: WORDPRESS_DB_HOST: db WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress EOF $ docker swarm init $ docker stack deploy -c stack.yaml mywordpress Creating network mywordpress_default Creating service mywordpress_wordpress Creating service mywordpress_db $ docker stack rm mywordpress To test it, browse http://127.0.0.1:8000 to see the workpress new user page. Creat the same app on ECS ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:0:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"Install ECS CLI sudo curl -Lo /usr/local/bin/ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest vi ecs_cli_gpg.txt # copy/paste Amazon ECS PGP public key gpg --import ecs_cli_gpg.txt curl -Lo ecs-cli.asc https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest.asc gpg --verify ecs-cli.asc /usr/local/bin/ecs-cli sudo chmod +x /usr/local/bin/ecs-cli $ ecs-cli -v ecs-cli version 1.21.0 (bb0b8f0) ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:1:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"Configuring ECS CLI Configuration information is stored in the ~/.ecs directory on macOS and Linux systems $ ecs-cli configure profile \\ --access-key $AWS_ACCESS_KEY_ID \\ --secret-key $AWS_SECRET_ACCESS_KEY # --profile-name dec $ cat ~/.ecs/credentials # created by above configure profile --profile-name dec command version: v1 default: default ecs_profiles: default: aws_access_key_id: \u003cAWS_ACCESS_KEY_ID\u003e aws_secret_access_key: \u003cAWS_SECRET_ACCESS_KEY\u003e $ ecs-cli configure \\ --cluster test-fargate-App \\ --region us-east-1 \\ --default-launch-type FARGATE # --config-name dec $ cat ~/.ecs/config # this file is created by above ecs-cli configure command version: v1 default: default clusters: default: cluster: test-fargate-App region: us-east-1 default_launch_type: FARGATE ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:2:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"Creat ECS Cluster This command “surprisingly” created a Cloudformation stack “amazon-ecs-cli-setup-test-fargate-App”. All this CF template deployed is a VPC, however the ECS cluster is created outside of this CF template. I believe if the default_launch_type is not FARGATE, the EC2 instances will be created since I do see them in the CF template with conditions. $ ecs-cli up # --cluster-config dec \\ # --ecs-profile dec ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:3:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"List and pull Images from ECR $ aws ecr --profile \u003cprofile\u003e --region eu-west-1 describe-repositories $ ecs-cli pull --aws-profile \u003cprofile\u003e \u003cAWS_ACCOUNT\u003e.dkr.ecr.us-east-1.amazonaws.com/my-ecr-repo:mytag INFO[0000] Getting AWS account ID... INFO[0000] Pulling image repository=\u003cAWS_ACCOUNT\u003e.dkr.ecr.us-east-1.amazonaws.com/my-ecr-repo tag=mytag INFO[0006] Image pulled $ docker images | tail -1 \u003cAWS_ACCOUNT\u003e.dkr.ecr.us-east-1.amazonaws.com/my-ecr-repo mytag 6c1f3809ea08 2 years ago 50.9MB ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:4:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"Create task definiation Following ecs-cli official repo to create 2 files. $ cat \u003c\u003cEOF \u003e docker-compose.yml version: '3' services: mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: wordpress: image: wordpress ports: - \"80:80\" EOF $ cat \u003c\u003cEOF \u003e ecs-params.yml version: 1 task_definition: ecs_network_mode: awsvpc task_size: mem_limit: 2GB cpu_limit: 512 run_params: network_configuration: awsvpc_configuration: subnets: - \"subnet-0f8e36255ab1ac868\" - \"subnet-0a38fe5a081e8eead\" assign_public_ip: ENABLED EOF $ Todo: using the following commands I should be able to create tasks and service. $ ecs-cli compose --project-name wordpress-test service create $ ecs-cli compose --project-name wordpress-test service ps ","date":"2023-03-14","objectID":"/k8s/docker_swarm_ecs/:5:0","tags":["AWS","Docker","Tips"],"title":"Docker_Swarm_ECS","uri":"/k8s/docker_swarm_ecs/"},{"categories":null,"content":"Control my newly create K8s Cluster from my Laptop Finally my bare-metal K8s Cluster is built. vma@MBP ~ % mkdir .kube vma@MBP ~ % scp -i ~/.ssh/vma_rsa 51:/home/vma/.kube/config .kube/config Enter passphrase for key '/Users/vma/.ssh/vma_rsa': config 100% 5640 350.9KB/s 00:00 vma@MBP ~ % kubectl cluster-info Kubernetes control plane is running at https://192.168.0.51:6443 CoreDNS is running at https://192.168.0.51:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. vma@MBP ~ % kubectl get no NAME STATUS ROLES AGE VERSION cp1 Ready control-plane 7d11h v1.26.0 k8s-52 Ready \u003cnone\u003e 7d10h v1.26.0 k8s-53 Ready \u003cnone\u003e 7d10h v1.26.0 k8s-54 Ready \u003cnone\u003e 7d10h v1.26.0 vma@MBP ~ % ls -l .kube total 16 drwxr-x---@ 4 vma staff 128 15 Mar 12:29 cache -rw------- 1 vma staff 5640 15 Mar 12:28 config vma@MBP ~ % wc -l .kube/config 19 .kube/config Connect to my AKS Cluster CSCluster Because I don’t have my AKS configured before connecting to my local K8s Cluster, this az aks get-credentials command added itself to .kube/config file for me. vma@MBP ~ % az aks get-credentials --resource-group \"Kubernetes-Cloud\" --name CSCluster Merged \"CSCluster\" as current context in /Users/vma/.kube/config vma@MBP ~ % wc -l .kube/config 32 .kube/config vma@MBP ~ % kubectl cluster-info Kubernetes control plane is running at https://cscluster-kubernetes-cloud-ab6151-jpcx0neb.hcp.eastus.azmk8s.io:443 CoreDNS is running at https://cscluster-kubernetes-cloud-ab6151-jpcx0neb.hcp.eastus.azmk8s.io:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Metrics-server is running at https://cscluster-kubernetes-cloud-ab6151-jpcx0neb.hcp.eastus.azmk8s.io:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. vma@MBP ~ % kubectl get no NAME STATUS ROLES AGE VERSION aks-nodepool1-23893820-vmss000000 Ready agent 11m v1.25.5 aks-nodepool1-23893820-vmss000001 Ready agent 12m v1.25.5 aks-nodepool1-23893820-vmss000002 Ready agent 12m v1.25.5 Switch between them vma@MBP ~ % kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * CSCluster CSCluster clusterUser_Kubernetes-Cloud_CSCluster kubernetes-admin@kubernetes kubernetes kubernetes-admin vma@MBP ~ % kubectl config use-context kubernetes-admin@kubernetes Switched to context \"kubernetes-admin@kubernetes\". vma@MBP ~ % kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE CSCluster CSCluster clusterUser_Kubernetes-Cloud_CSCluster * kubernetes-admin@kubernetes kubernetes kubernetes-admin vma@MBP ~ % kubectl get no NAME STATUS ROLES AGE VERSION cp1 Ready control-plane 7d11h v1.26.0 k8s-52 Ready \u003cnone\u003e 7d10h v1.26.0 k8s-53 Ready \u003cnone\u003e 7d10h v1.26.0 k8s-54 Ready \u003cnone\u003e 7d10h v1.26.0 Delete the AKS cluster won’t… This command won’t modify .kube/config file and remove itself. The context still existing after and you can still use it, just it won’t be able to connect because the actually cluster is gone. $ az aks delete --resource-group \"Kubernetes-Cloud\" --name CSCluster Are you sure you want to perform this operation? (y/n): y ","date":"2023-03-13","objectID":"/k8s/local_kubectl_contexts/:0:0","tags":["Azure","K8s","Tips"],"title":"Local_kubectl_contexts","uri":"/k8s/local_kubectl_contexts/"},{"categories":null,"content":"UEFI bios and Linux Server Installing Linux server on HP Desktop with UEFI feature. Expensive lessson I have learned: Everytime installation failed after it start to copy files, I have tested all kinds of different ways, and it turn out the problem is UEFI. Updated the the next day: The problem wasn’t solved this way, I just installed Ubuntu Desktop, that solved the problem. From BIOS -\u003e Boot Order, you can disable the whole UEFI feature here ","date":"2023-03-07","objectID":"/bare_metal_linux/:1:0","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Modifications after install ","date":"2023-03-07","objectID":"/bare_metal_linux/:2:0","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Change IP address with netplan When installing the OS, I choosed DHCP. After installed successfully, set it statci like this: $ cat /etc/netplan/00-installer-config.yaml # This is the network config written by 'subiquity' n#etwork: ethernets: eno1: dhcp4: no addresses: - 192.168.0.53/24 nameservers: addresses: [8.8.8.8, 1.1.1.1] routes: - to: default via: 192.168.0.1 version: 2 renderer: networkd $ sudo netplan apply ","date":"2023-03-07","objectID":"/bare_metal_linux/:2:1","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Correct your hostname sudo hostnamectl set-hostname [NEW_HOSTNAME] ","date":"2023-03-07","objectID":"/bare_metal_linux/:2:2","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Download public key from github `#``bash $ curl https://api.github.com/users/decmaxn/keys | jq -r .[].key | tee .ssh/authorized_keys ## Local SSH private key and configuration ```bash $ eval \"$(ssh-agent -s)\" $ ssh-add ~/.ssh/vma_rsa # the vma_rsa file can't be 755, 600 works. $ ssh-add -l # confirm the key is in memory $ cat ~/.ssh/config Host 192.168.0.* User vma IdentityFile ~/.ssh/vma_rsa Host 51 Hostname 192.168.0.51 Host 52 Hostname 192.168.0.52 Host 53 Hostname 192.168.0.53 Host 54 Hostname 192.168.0.54 $ ssh 51 ","date":"2023-03-07","objectID":"/bare_metal_linux/:2:3","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Check network speed sudo apt-get install curl curl -s https://packagecloud.io/install/repositories/ookla/speedtest-cli/script.deb.sh | sudo bash sudo apt-get install speedtest ","date":"2023-03-07","objectID":"/bare_metal_linux/:3:0","tags":["Linux","Deploy","tips","OS","DataCenter","H/W"],"title":"Bare_metal_linux","uri":"/bare_metal_linux/"},{"categories":null,"content":"Thank you, Cloud. Started to learn go, I feel that I have to review my Kubernetes (K8s) skills. Cloned my old K8s Lab repo, starting up the lab environment using VirtualBox and Vagrant, I thought it would be like riding a bike. However, things didn’t go as smoothly as I had hoped. I spent hours struggling to make things work with current versions of everything, which is expected. After that the same laptop doesn’t work as good as before, encountering errors left and right, waiting there for CPU to come down to normal, worrying that my old laptop might be too dirty, that the high temperature is slowing down it mor and feeling completely out of my depth. As I sat there, exhausted and relieved, I realized that I had taken cloud computing for granted. With the cloud, for years I never had to worry about setting up my own environment, or dealing with the headaches of local development. Everything just worked, seamlessly and effortlessly. Now I took out my dusty desktops, decided to build a bare metal K8s cluster. With all the time I spent on this virtual lab, why not build a proper physical lab :-) ","date":"2023-03-06","objectID":"/thankyou_cloud/:0:0","tags":null,"title":"Thankyou_cloud","uri":"/thankyou_cloud/"},{"categories":null,"content":"This is with the same requirment, an updated version of Build K8s Cluster 1 Control Plan, which is tested on Ubuntu 20.04 LTS. Common install and config for all cluster nodes # Load two modules and configure them to load on boot # Linux 文件系统层叠内核模块,将多个文件系统合并成一个只读文件系统，并在其上添加一个可写层 sudo modprobe overlay # Linux 网络地址转换（NAT）和 IP 数据包过滤器内核模块，允许容器与宿主机和其他容器之间进行网络通信 sudo modprobe br_netfilter cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/containerd.conf \u003e/dev/null overlay br_netfilter EOF # Add sysctl settings 内核参数（Kernel Parameters） cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf \u003e/dev/null net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF # 在不需要重启系统的情况下重新加载 /etc/sysctl.conf 和 /etc/sysctl.d 文件中的所有设置 sudo sysctl --system \u003e/dev/null 2\u003e\u00261 # Disable swap - actuqally disabled by vagrant already sed -i '/swap/d' /etc/fstab swapoff -a # Install containerd...we need to install from the docker repo to get containerd 1.6, the ubuntu repo stops at 1.5.9 # 用GPG 工具将下载的密钥进行解析（解码），并将其保存GPG 工具将下载的密钥进行解析（解码），并将其保存 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/docker.gpg echo \"deb [arch=$(dpkg --print-architecture)signed-by=/etc/apt/trusted.gpg.d/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs)stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null sudo apt-get update -q \u003e/dev/null sudo apt-get install -q -y containerd.io \u003e/dev/null containerd --version # Enable containerd service sudo mkdir -p /etc/containerd sudo containerd config default | sudo tee /etc/containerd/config.toml \u003e/dev/null # 使用 cgroup driver，容器可以在系统中独立地运行和使用资源，而不会对其他容器或宿主机造成干扰 #Set the cgroup driver for containerd to systemd which is required for the kubelet. #For more information on this config file see: # https://github.com/containerd/cri/blob/master/docs/config.md and also # https://github.com/containerd/containerd/blob/master/docs/ops.md # Set the cgroup driver for containerd to systemd, because ubuntu is systemd system sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml grep SystemdCgroup /etc/containerd/config.toml sudo systemctl restart containerd # Add Google's apt repository gpg key curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - sudo bash -c 'cat \u003c\u003cEOF \u003e/etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF' # Install Kubernetes sudo apt-get -q update \u003e/dev/null #Install the required packages, if needed we can request a specific version. # apt-cache policy kubelet | head -n 20 #Use this version because in a later course we will upgrade the cluster to a newer version. VERSION=1.26.0-00 sudo apt-get -q install -y kubelet=$VERSION kubeadm=$VERSION kubectl=$VERSION \u003e/dev/null sudo apt-mark hold kubelet kubeadm kubectl containerd \u003e/dev/null # Start and Enable kubelet and containerd services #The kubelet will enter a crashloop until a cluster is created or the node is joined to an existing cluster. # sudo systemctl status kubelet.service # sudo systemctl status containerd.service sudo systemctl enable kubelet.service \u003e/dev/null 2\u003e\u00261 sudo systemctl enable containerd.service \u003e/dev/null 2\u003e\u00261 Control Plane nodes 以上步骤需要在所有 kubernetes 节点里做， 下面只属于 control plane 节点 #Generate a default kubeadm init configuration file...this defines the settings of the cluster being built. #If you get a warning about how docker is not installed...this is OK to ingore and is a bug in kubeadm #For more info on kubeconfig configuration files see: # https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file kubeadm config print init-defaults | tee ClusterConfiguration.yaml \u003e/dev/null #Change the address of the localAPIEndpoint.advertiseAddress to the Control Plane Node's IP address sed -i 's/ advertiseAddress: 1.2.3.4/ advertiseAddress: 172.16.94.10/' ClusterConfiguration.yaml #Set the CRI Socket to point to containerd, I foun","date":"2023-03-05","objectID":"/k8s/build-k8s-cluster-2023-control-plan/:0:0","tags":["K8s","course"],"title":"Build K8s Cluster 2023 Control Plan","uri":"/k8s/build-k8s-cluster-2023-control-plan/"},{"categories":null,"content":"Don’t just upgrade virtualbox to the latest when work with vagrant Check Vagrant official Doc for compatible version of Virtualbox. I have found misleading information from other places. Now I have to downgrade Virtualbox. # Uninstall current version of virtualbox 7 choco uninstall virtualbox # Search available versions choco search virtualbox --exact --all-versions # Install a compatible version choco install virtualbox --version=6.1.42 --force ","date":"2023-03-04","objectID":"/downgrade_virtualbox_for_vagrant/:0:0","tags":["Vagrant","Virtualbox","tips"],"title":"Downgrade_virtualbox_for_vagrant","uri":"/downgrade_virtualbox_for_vagrant/"},{"categories":null,"content":"Note for all nodes below, we have to install and configure kubernetes following “Build K8s Cluster 1 Control Plan” NFS service NFS server hostname is c1-storage, IP is 172.16.94.5. # Install NFS server and prepare export path sudo apt install -y nfs-kernel-server sudo mkdir -p /export/volumes sudo mkdir /export/volumes/pod # Configure our NFS Export in /etc/export for /export/volumes to (*) all IPs, with (rw) write permission # Using no_root_squash because in the demo we are going to mount it with root access. # and no_subtree_check to allow applications to mount subdirectories of the export directly. sudo bash -c 'echo \"/export/volumes *(rw,no_root_squash,no_subtree_check)\" \u003e /etc/exports' cat /etc/exports sleep 2 sudo systemctl restart nfs-kernel-server.service worker nodes From the control plane, run kubeadm token create --print-join-command \u003e /joincluster.sh to create a script for worker node to join it. # Join worker nodes to the Kubernetes cluster sudo apt-get install -q -y sshpass \u003e/dev/null 2\u003e\u00261 sshpass -p \"vagrant\" scp -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no vagrant@c1-cp1.example.com:/joincluster.sh /joincluster.sh bash /joincluster.sh \u003e/dev/null 2\u003e\u00261 # Join worker nodes to the Kubernetes cluster sudo apt install -y nfs-common ","date":"2023-03-04","objectID":"/k8s/build-k8s-cluster-2-worker-nfs/:0:0","tags":["K8s","course"],"title":"Build K8s Cluster 2 Worker Nfs","uri":"/k8s/build-k8s-cluster-2-worker-nfs/"},{"categories":null,"content":"Here are steps from a training course long time ago to install configure K8s control plane: control plan hostname is c1-cp1, other nodes will be c1-node# and c1-storage control plan IP is 172.16.94.10, other nodes will be 11, 12…. the pod network is 172.172.0.0/16 to not overlay with my lap network. All nodes have user vagrant for install, configure and maintain k8s cluster Common install and config for all cluster nodes The following scripts is modified to work with new versions of everything, refer to Link # Linux 文件系统层叠内核模块,将多个文件系统合并成一个只读文件系统，并在其上添加一个可写层 sudo modprobe overlay # Linux 网络地址转换（NAT）和 IP 数据包过滤器内核模块，允许容器与宿主机和其他容器之间进行网络通信 sudo modprobe br_netfilter cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/containerd.conf \u003e/dev/null overlay br_netfilter EOF # Add sysctl settings 内核参数（Kernel Parameters） cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf \u003e/dev/null net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF # 在不需要重启系统的情况下重新加载 /etc/sysctl.conf 和 /etc/sysctl.d 文件中的所有设置 sudo sysctl --system \u003e/dev/null 2\u003e\u00261 # Disable swap sed -i '/swap/d' /etc/fstab swapoff -a # Install the latest containerd using apt package sudo apt-get update -q \u003e/dev/null sudo apt-get install -q -y containerd \u003e/dev/null # Enable containerd service sudo mkdir -p /etc/containerd sudo containerd config default | sudo tee /etc/containerd/config.toml \u003e/dev/null # Set the cgroup driver for containerd to systemd, because ubuntu is systemd system # 使用 cgroup driver，容器可以在系统中独立地运行和使用资源，而不会对其他容器或宿主机造成干扰 sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml grep SystemdCgroup /etc/containerd/config.toml sudo systemctl restart containerd # Add Google's apt repository gpg key curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - sudo bash -c 'cat \u003c\u003cEOF \u003e/etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF' # Install Kubernetes 1.21 (kubeadm, kubelet and kubectl) sudo apt-get -q update \u003e/dev/null #Install the required packages, if needed we can request a specific version. #Use this version because in a later course we will upgrade the cluster to a newer version. VERSION=1.21.0-00 sudo apt-get -q install -y kubelet=$VERSION kubeadm=$VERSION kubectl=$VERSION \u003e/dev/null sudo apt-mark hold kubelet kubeadm kubectl containerd \u003e/dev/null # Start and Enable kubelet and containerd services sudo systemctl enable kubelet.service \u003e/dev/null 2\u003e\u00261 sudo systemctl enable containerd.service \u003e/dev/null 2\u003e\u00261 Control Plane nodes 以上步骤需要在所有 kubernetes 节点里做， 下面只属于 control plane 节点 The following scripts is modified to work with new versions of everything, refer to Link # Initialize Kubernetes with kubeadm command kubeadm config print init-defaults | tee ClusterConfiguration.yaml \u003e/dev/null sed -i 's/ advertiseAddress: 1.2.3.4/ advertiseAddress: 172.16.94.10/' ClusterConfiguration.yaml sed -i 's/ criSocket: \\/var\\/run\\/dockershim\\.sock/ criSocket: \\/run\\/containerd\\/containerd\\.sock/' ClusterConfiguration.yaml sed -i 's/ name: node/ name: c1-cp1/' ClusterConfiguration.yaml sed -i '/serviceSubnet: /a \\ podSubnet: 172.172.0.0/16\\' ClusterConfiguration.yaml cat \u003c\u003cEOF | cat \u003e\u003e ClusterConfiguration.yaml --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration cgroupDriver: systemd EOF sudo kubeadm init \\ --config=ClusterConfiguration.yaml \\ --cri-socket /run/containerd/containerd.sock # Copy Kube admin config prepare to use kubectl command for calico network mkdir /home/vagrant/.kube cp /etc/kubernetes/admin.conf /home/vagrant/.kube/config chown -R vagrant:vagrant /home/vagrant/.kube # Deploy calico network wget https://docs.projectcalico.org/manifests/calico.yaml \u003e/dev/null 2\u003e\u00261 su - vagrant -c \"kubectl apply -f calico.yaml\" # Kubectl command completion. No need to do this on worker nodes since we use this control plane node as work bench. sudo apt-get install -y bash-completion echo \"source \u003c(kubectl completion bash)\"","date":"2023-03-03","objectID":"/k8s/build-k8s-cluster-1-control-plan/:0:0","tags":["K8s","course"],"title":"Build K8s Cluster 1 Control Plan","uri":"/k8s/build-k8s-cluster-1-control-plan/"},{"categories":null,"content":"Develop Docker appliation in Windows workspace? Don’t expect to see AWS created public Images based on Windows 10 Desktop, they are all Windows Server based. However, I get myself into installing Docker Desktop on a “Windows 10(Server 2019 based)” workspace. Just wan to know if it works. ","date":"2023-03-02","objectID":"/docker_on_aws_workspace/:0:0","tags":["AWS","Docker","tips"],"title":"AWS_Workspace","uri":"/docker_on_aws_workspace/"},{"categories":null,"content":"Create workspace Profile=\u003cprofile\u003e Region=\u003cregion\u003e # existing Directory Service dreictory $ aws ds --profile $Profile --region $Region \\ describe-directories --query 'DirectoryDescriptions[].DirectoryId' # exsiting bundles $ aws workspaces --profile $Profile --region $Region \\ describe-workspace-bundles --query 'Bundles[].BundleId' export DirectoryId = \u003c\u003e export BundleId = \u003c\u003e # Creat a workspace with existing user and bundle. $ aws workspaces --profile $Profile --region $Region \\ create-workspaces --workspace \\ DirectoryId=$DirectoryId,\\ UserName=\u003cUserName\u003e,\\ BundleId=$BundleID # Describe the workspace $ aws workspaces --profile $Profile --region $Region describe-workspaces \\ --query 'Workspaces[?UserName==`\u003cUserName\u003e`]' # Migrate to another existing bundle $ aws workspaces --profile $Profile --region $Region migrate-workspace \\ --source-workspace-id \u003cworkspaceID just been created\u003e \\ --bundle-id \u003canother bundle id\u003e # Change size of the workspace $ aws workspaces --profile $Profile --region $Region \\ modify-workspace-properties \\ --workspace-id \u003cworkspaceID just been created\u003e \\ --workspace-properties ComputeTypeName=PERFORMANCE An error occurred (InvalidResourceStateException) when calling the ModifyWorkspaceProperties operation: Action not supported. Property update not allowed within 21,600 seconds of creation. #6 hours ","date":"2023-03-02","objectID":"/docker_on_aws_workspace/:1:0","tags":["AWS","Docker","tips"],"title":"AWS_Workspace","uri":"/docker_on_aws_workspace/"},{"categories":null,"content":"install Docker Desktop Install workspace client on Windows with Choco. choco install amazon-workspaces Follow Amazon WorkDocs Drive to share files between local computer and workspace. After remote into the workspace, I used choco to install docker desktop. It completes successfully. However, it can’t be started and complains about hyperV. I found by systeminfo command that hyperV is installed. Hyper-V Requirements: A hypervisor has been detected. Features required for Hyper-V will not be displayed. Solution According to official AWS document “Containers and Windows subsystem for Linux on Amazon WorkSpaces” In cases where customer requirements mandate enabling containers using Amazon WorkSpaces, a technical how-to has been published that enables the use of Docker. Customers should be informed that this requires other trailing services, and that there are increased costs and complexity when compared with decoupled, native container services. That end my advanture. ","date":"2023-03-02","objectID":"/docker_on_aws_workspace/:2:0","tags":["AWS","Docker","tips"],"title":"AWS_Workspace","uri":"/docker_on_aws_workspace/"},{"categories":null,"content":"Install Azure Cli Install on Windows with choco install azure-cli, or in linux as below: $ AZ_REPO=$(lsb_release -cs) $ echo \"deb [arch=amd64] https://packages.microsoft.com/repos/$azure-cli/ $AZ_REPOmain\" | sudo tee /etc/apt/sources.list.d/$ azure-cli.list $ curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg $ --dearmor | sudo tee /etc/apt/trusted.gpg.d/microsoft.gpg \u003e /dev/$ null $ sudo apt-get update $ sudo apt-get install azure-cli Create a AKS cluster $ az login $ az account set --subscription \"Visual Studio Professional Subscription\" $ az group create --name \"Kubernetes-Cloud\" --location eastus $ az aks get-versions --location eastus -o table # let use 1.25.5 $ az aks create \\ --resource-group \"Kubernetes-Cloud\" \\ --generate-ssh-keys \\ --name CSCluster \\ --kubernetes-version 1.25.5 \\ # no need to --node-count 3 #default Node count is 3 or az login az account set -s \"Visual Studio Professional Subscription\" # Create an RG and AKS cluster first az group create -l eastus -n Kubernetes-Cloud az aks create -g Kubernetes-Cloud -n CSCluster --generate-ssh-keys Install and config Kubectl # az aks install-cli # not necessary in my case $ az aks get-credentials --resource-group \"Kubernetes-Cloud\" --name CSCluster Merged \"CSCluster\" as current context in /home/vma/.kube/config $ kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * CSCluster CSCluster clusterUser_Kubernetes-Cloud_CSCluster or # Get the credentials and check the connectivity # az aks install-cli # not necessary in my case az aks get-credentials -g Kubernetes-Cloud -n CSCluster --overwrite-existing kubectl get nodes az aks scale -g Kubernetes-Cloud -n CSCluster --node-count 1 PS C:\\\u003e kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE * CSCluster CSCluster clusterUser_Kubernetes-Cloud_CSCluster kubernetes-admin@kubernetes kubernetes kubernetes-admin Check created Cluster and clean up # kubectl config use-context CSCluster # No need since there is only one context in my case $ kubectl get nodes NAME STATUS ROLES AGE VERSION aks-nodepool1-30040660-vmss000000 Ready agent 6m59s v1.25.5 aks-nodepool1-30040660-vmss000001 Ready agent 7m9s v1.25.5 aks-nodepool1-30040660-vmss000002 Ready agent 7m4s v1.25.5 $ kubectl get pods --all-namespaces Create ACR and repo, images, tags # 创建 ACR registry az acr create -n myacr -g $RG --sku Basic # SKU：Basic、Standard、Premium az acr list -o table # 现在，我们将从 Docker 存储库导入 hello-world 映像 az acr import -n myacr --source docker.io/library/hello-world:latest -t hello-world-backup:1.0.0 # 我们现在有一个存储库, 一个映像, 一个标签 az acr repository list -n myacr -o table az acr repository show -n myacr --repository hello-world-backup -o table az acr repository show-tags -n myacr --repository hello-world-backup -o table # 重新导入一个新标签的镜像，再导入另一个镜像 az acr import -n myacr --source docker.io/library/hello-world:latest -t hello-world-backup:1.1.0 az acr import -n myacr --source docker.io/library/nginx:latest --image nginx:v1 # 克隆一个来自GitHub的示例项目, 而且直接build这个docker image git clone https://github.com/Azure-Samples/acr-build-helloworld-node az acr build --registry myacr --image helloacrtasks:v1 acr-build-helloworld-node Deploy a Image to the new Cluster # 获取我们的ACR登录服务器 az acr show -n myacr -o table $loginServer=(az acr show -n myacr --query loginServer) # 新建一个命名空间, 便于留用Cluster 的 Clean up. # kubectl create namespace acr # kubectl config set-context --current --namespace acr # 创建一个deployment kubectl create deployment nginx --image=$loginServer/nginx:v1 # 检查部署是否成功, 得到 Access Denied Error kubectl get deployment kubectl get pods kubectl describe pod (kubectl get pods -o=jsonpath='{.items[0].metadata.name}') # 解决以上问题，需要将ACR附加到AKS群集（也可以在创建时完成） kubectl delete deployment nginx az aks update -n CSCluster -g Kubernetes-Cloud --attach-acr myacr # 再次部署deployment，成功 kubectl create deployment nginx --image=$loginServer/nginx:v1 kubectl get deployment,pods Clean up $ az aks delete --resource-group \"Kubernetes-Cloud\" --name CSCluster #--yes --no-wait ","date":"2023-03-01","objectID":"/k8s/aks_install/:0:0","tags":["Azure","K8s","course"],"title":"AKS_install","uri":"/k8s/aks_install/"},{"categories":null,"content":".devcontainer Run vscode command palette, Dev Conainter and search universal, this way to get Codespaces default container. Later on add pwsh. TDD: Test-driven development Follow Hello world to practice TDD. ","date":"2023-02-26","objectID":"/go/devcontainer_tdd/:0:0","tags":["coding","Go","course"],"title":"Devcontainer_tdd","uri":"/go/devcontainer_tdd/"},{"categories":null,"content":"Map Map can store any types key and value pairs, there is no order. There is no fixed size, and you can tell it’s a pointer. We have to give map key word to tell it’s type, it’s not like this before. Follow that is key type in [] and value type. m := map[string]int{\"foo\": 1, \"bar\": 2} fmt.Println(m) // map[bar:2 foo:1] fmt.Println(m[\"foo\"]) // 1 m[\"foo\"] = 11 // modify fmt.Println(m[\"foo\"]) // 11 delete(m, \"foo\") // delete a key value pair fmt.Println(m) // map[bar:2] fmt.Println(m[\"foo\"]) // 0 Access a non-exist key will return 0, so check your return Struct Similar to python’s dictionary. This is the only data type allow to associate disparate types together. Map’s keys have to be same type, and values have to be the same type, although can be different with keys. type user struct { // define a struct type named as user ID int // define the fields it's going to contain FirstName string LastName string } var u user // fmt.Println(u) // {0 } u exit with zero values. // Zero value of int is 0, string is a blank string u.ID = 11 u.FirstName = \"Elon\" fmt.Println(u, u.FirstName) // {11 Elon } Elon u2 := user{ID: 22, FirstName: \"Elon2\", LastName: \"Musk\"} fmt.Println(u2) // {22 Elon2 Musk} Note, when doing this in multiple lines, Go’s automatic semicolon insertion is going to make problem. You’d better add a comma after the last item. u2 := user{ ID: 22, FirstName: \"Elon2\", LastName: \"Musk\", // last item } fmt.Println(u2) ","date":"2023-02-26","objectID":"/go/map/:0:0","tags":["coding","Go","course"],"title":"Map","uri":"/go/map/"},{"categories":null,"content":"Array It’s similar with Python’s array. In Go, array is also a continues memoery block in fixed size, so it’s faster but not dynamic. It also stores same type objects. What different is Go array is not a pointer. var myarray [3]int // signature of array is [size]type fmt.Println(myarray) // [0 0 0] myarray[0] = 3 fmt.Println(myarray[0]) // 3 arr := [3]int{1, 2, 3} // declare implicitly, it's not [1 2 3] fmt.Println(arr) // [1 2 3] Slice Slice from an array, or another slice myslice := arr[:] // implicitly, : means from index 0 to last fmt.Println(myslice) // [1 2 3] myslice2 := arr[:2] // from index 0 to 2, not inclusive fmt.Println(myslice2) // [1 2] myslice3 := arr[1:] // from index 1 to last fmt.Println(myslice3) // [2 3] arr[0] = 11 myslice2[1] = 22 fmt.Println(arr, myslice, myslice2) //they point to the same // [11 22 3] [11 22 3] [11 22] Since most of time you work with slice only, you don’t really care about array under it as long as it is managed for you. slice := []int{1, 2, 3} // note you didn't mention size fmt.Println(slice) // [1 2 3] slice = append(slice, 4, 5) // what happen if run out of space fmt.Println(slice) // [1 2 3 4 5] Go will copy the array to anohter place if it run out of continues space, we don’t need to worry about that under normal circumstances. ","date":"2023-02-26","objectID":"/go/array_slice/:0:0","tags":["coding","Go","course"],"title":"Array_slice","uri":"/go/array_slice/"},{"categories":null,"content":"Normal features of Go constant Normal side of Go constant: declare and assign at the same time, can not be done separately. Value has to be determined in complie time, not run time The type of constant can be implicit, or explicit if you need to const pi = 3 // type not assigned fmt.Println(pi) // pi is treated as int fmt.Println(pi + 0.14) // pi is treated as float pi = 3.1415 // you can change value of a constant //./main.go:10:5: cannot assign to pi Iota Constant block, you can have multiple of them and iota will start from 0 in each block. const ( pi = 3 greeting = \"hello\" ) You can build long chain of constants using iota. const ( Monday = iota // 0 iota starts at 0 and increase by 1 every time it is used Tuesday // 1 reuse the constant expression above, Wednesday // 2 which is simply iota Thursday // 3 Friday // 4 Saturday // 5 Sunday // 6 ) You can also use complex constant expresssion const ( _ = iota // Ignore the first iota, which is 0 KB = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10 * 1)，bit shift operator MB // 1 \u003c\u003c (10 * 2)，same as 1 times 2^20 GB // 1 \u003c\u003c (10 * 3)，2^10 = 1024... TB // 1 \u003c\u003c (10 * 4)， ) The purpose of iota is for convinient. ","date":"2023-02-26","objectID":"/go/constant/:0:0","tags":["coding","Go","course"],"title":"Constant","uri":"/go/constant/"},{"categories":null,"content":"Declaring var with Primitive Data Types Easy to understand way: var num int num = 11 fmt.Println(num) Esay to write way: var num int = 11 var greeting string = \"Hello\" fmt.Println(num, greeting) Normal way: num := 11 greeting := \"Hello\" fmt.Println(num, greeting) declaring multiple vars at the same time // Declare three integer variables named \"x\", \"y\", and \"z\" with initial values of 1, 2, and 3, respectively x, y, z := 1, 2, 3 fmt.Println(x, y, z) // var x, y, z int = 1, 2, 3 x, y, z := 1, \"hello\", true fmt.Println(x, y, z) Pointers Like in python, big and complex objects are natively pointer, like Slice, Map, Function. Small of simple objects are not, like int, bool, string, array. Go has a interesting feature to expose this machenisim. For example, declare a var “prt” point to a string variable. var prt *string // * is pointer operator fmt.Println(prt) // \u003cnil\u003e This is an empty pointer, since prt has not been initiallized var greeting string = \"hello\" prt = \u0026greeting // \u0026 is \"address operator\". fmt.Println(prt) // 0xc0000741e0 address of greet var Using dereference operator in ‘*prt’ expression access the varlue of string var “greeting”. *prt = \"world\" // * is dereference operator fmt.Println(greeting) // world - no longer hello However, if you haven’t initialize prt var, it’s going to fail. var prt2 *string *prt2 = \"world\" fmt.Println(*prt2) // panic: runtime error: invalid memory address or nil pointer dereference One way to fix it without create a string var is: var prt2 *string = new(string) *prt2 = \"world\" fmt.Println(*prt2) Since pointer arithmetic is dangous, Go doesn’t allow it. ","date":"2023-02-26","objectID":"/go/var_primitives_pointer/:0:0","tags":["coding","Go","course"],"title":"Var_primitives_pointer","uri":"/go/var_primitives_pointer/"},{"categories":null,"content":"Installation download Go itself for windows and install, confirm with go version after. go version go1.20.1 windows/amd64 ","date":"2023-02-25","objectID":"/go/install-config/:0:0","tags":["coding","Go","course"],"title":"Install Config","uri":"/go/install-config/"},{"categories":null,"content":"Use “go help doc” for more information about doc command \u003e go doc json.Decoder.Decode package json // import \"encoding/json\" func (dec *Decoder) Decode(v any) error Decode reads the next JSON-encoded value from its input and stores it in the value pointed to by v. See the documentation for Unmarshal for details about the conversion of JSON into a Go value. json package, Decoder object within json package, and Decode method on that Decoder object. Install vscode using choco and confirmed with choco list -l vscode 1.70.1 vscode.install 1.70.1 After installing golang.go extension. Got a prompt to install the gopls and go-ouitline. code --install-extension golang.go Now, try creat a hello world program and try to features of those tool type pack to see it suggests {}package main type fm to see it suggests func main{} type fmt.Println(“Hello world!\") slowly to see it suggests the rest. save this file to see it added import “fmt” start a terminal and use go run . to see it runs properly. Also create a project and try it. $ go mod init github.com/decmaxn/goLab go: creating new go.mod: module github.com/decmaxn/goLab $ go run github.com/decmaxn/goLab Hello world! ","date":"2023-02-25","objectID":"/go/install-config/:1:0","tags":["coding","Go","course"],"title":"Install Config","uri":"/go/install-config/"},{"categories":null,"content":"Why Git can be used for managing changes to other types of files, such as documents. For documents related to code and infra, Confluence can be just a publshing system, while the Version tracking, Collaboration, Branching and Backup happens at Git side. There should be a CICD pipeline to deploy changes to Confluence. Instruction Confluence Publisher can be used for this purpose. Refer to it’s Github for details. Also Docker Image seems to be updated recently as well. docker pull confluencepublisher/confluence-publisher:0.0.0-SNAPSHOT export BUILD_SOURCESDIRECTORY=$(pwd) export ROOT_CONFLUENCE_URL=https://hotmailbox.atlassian.net/wiki/home export USERNAME=hotmailbox@hotmail.com export PASSWORD=\u003ctobereplaced\u003e export SPACE_KEY=\u003cto be replaced\u003e export ANCESTOR_ID=327681 export PUBLISHING_STRATEGY=APPEND_TO_ANCESTOR docker run --rm -v $BUILD_SOURCESDIRECTORY/$CONSOLIDATED_FOLDER_NAME/docs/:/var/asciidoc-root-folder -e ROOT_CONFLUENCE_URL=$ROOT_CONFLUENCE_URL \\ -e SKIP_SSL_VERIFICATION=false \\ -e USERNAME=$USERNAME \\ -e PASSWORD=$PASSWORD \\ -e SPACE_KEY=$SPACE_KEY \\ -e ANCESTOR_ID=$GITHUB_ANCESTOR_ID \\ -e PUBLISHING_STRATEGY=$PUBLISHING_STRATEGY \\ confluencepublisher/confluence-publisher:0.0.0-SNAPSHOT Details If you are registered as Confluence with microsoft or gmail account, the USERNAME and PASSWORD are your email address and email password. Also replace hotmailbox above with your mailbox name. SPACE_KEY can be found at at Confluence “space settings” page and “Space details” link. ANCESTOR_ID is the parent page’s ID, can be founded in the URL after /pages/when you open that page. etc. 327681 https://hotmailbox.atlassian.net/wiki/spaces/~xxxxxxxxxx/pages/327681/Manually+created+Doc-+Test For PUBLISHING_STRATEGY I can only find APPEND_TO_ANCESTOR. Troubleshooting Trying to fix the following error, I found out details above. in thread \"main\" java.lang.IllegalArgumentException: No enum constant org.sahli.asciidoc.confluence.publisher.client.PublishingStrategy.UPDATE in thread \"main\" java.lang.IllegalArgumentException: No enum constant org.sahli.asciidoc.confluence.publisher.client.PublishingStrategy.UPDATE_OR_CREATE in thread \"main\" java.lang.IllegalArgumentException: No root page found, but 'REPLACE_ANCESTOR' publishing strategy requires one single root page in thread \"main\" java.lang.IllegalArgumentException: No enum constant org.sahli.asciidoc.confluence.publisher.client.PublishingStrategy.APPEND_ANCESTOR in thread \"main\" org.sahli.asciidoc.confluence.publisher.client.http.RequestFailedException: request failed response: 401 Unauthorized Basic authentication with passwords is deprecated. For more information, see: https://developer.atlassian.com/cloud/confluence/deprecation-notice-basic-auth/, reason: \u003cnone\u003e) But the last error lead me to the following error. The deprecation period for this functionality has ended. From June 3rd, 2019, we will be progressively disabling the usage of this authentication method. If you are using a REST endpoint in Confluence with basic authentication, update your app or integration to use API tokens, OAuth, or Atlassian Connect. Conclusion The purpose of this test is to prove the idea, although the tool seems be outdated, I believe is archieved. ","date":"2023-02-20","objectID":"/git_controlled_doc_on_confluence/:0:0","tags":["devops","git","tips"],"title":"Git_controlled_doc_on_confluence","uri":"/git_controlled_doc_on_confluence/"},{"categories":null,"content":"Meet SHA1 Every Object in Git has its own SHA1. SHA1 are unique in the universe?! This cryptograph concept and technology is also used for bitcoin. :~$ mkdir gitdemo :~$ cd gitdemo/ :~/gitdemo$ echo \"Apple Pie\" | git hash-object --stdin # Create a SHA1. 23991897e13e47ed0adb91a0082c31c82fe0cbe5 :~/gitdemo$ echo \"Apple Pie\" | git hash-object --stdin -w # -w write it to GIT repository. fatal: Not a git repository (or any of the parent directories): .git :~/gitdemo$ git init # Create a workplace Initialized empty Git repository in /home/vma/gitdemo/.git/ :~/gitdemo$ ls -a . .. .git # .git makes it a repo and keeping every thing in. :~/gitdemo$ echo \"Apple Pie\" | git hash-object --stdin -w # it works now after the workplace is created 23991897e13e47ed0adb91a0082c31c82fe0cbe5 :~/gitdemo$ ls -la .git/objects/23/991897e13e47ed0adb91a0082c31c82fe0cbe5 # the file created -r--r--r-- 1 vma vma 26 Jun 4 14:13 .git/objects/23/991897e13e47ed0adb91a0082c31c82fe0cbe5 :~/gitdemo$ git cat-file 23991897e13e47ed0adb91a0082c31c82fe0cbe5 -t # Type of the SHA1 blob :~/gitdemo$ git cat-file 23991897e13e47ed0adb91a0082c31c82fe0cbe5 -p # Content of the SHA1 Apple Pie Content Tracker Let’s make a commit with 3 files, in 2 folders. Two of the files have same content. :~$ mkdir gitdemo1 :~$ cd gitdemo1 :~/gitdemo1$ echo \"Apple Pie\" \u003e menu.txt # Content is same with recipes/apple_pie.txt :~/gitdemo1$ mkdir recipes :~/gitdemo1$ echo \"One receipe per file please\" \u003e recipes/README.txt :~/gitdemo1$ echo \"Apple Pie\" \u003e recipes/apple_pie.txt :~/gitdemo1$ git init # The .git directory has nothing new Initialized empty Git repository in /home/vma/gitdemo1/.git/ :~/gitdemo1$ git status # GIT doesn't know what to do with these files On branch master Initial commit Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) menu.txt recipes/ nothing added to commit but untracked files present (use \"git add\" to track) :~/gitdemo1$ git add menu.txt # file can be added :~/gitdemo1$ git add recipes/ # Directory and files under it can be added :~/gitdemo1$ git status On branch master Initial commit Changes to be committed: (use \"git rm --cached \u003cfile\u003e...\" to unstage) new file: menu.txt new file: recipes/README.txt new file: recipes/apple_pie.txt :~/gitdemo1$ git commit -m \"First commit!\" [master (root-commit) acc3790] First commit! 3 files changed, 3 insertions(+) create mode 100644 menu.txt create mode 100644 recipes/README.txt create mode 100644 recipes/apple_pie.txt :~/gitdemo1$ git log commit acc3790dd4196ddb0109da375f44574b36ac42f3 Author: Your Name \u003cyou@example.com\u003e Date: Sun Jun 4 14:29:05 2017 -0400 First commit! Let’s see the content, and type. :~/gitdemo1$ cd .git ; tree objects objects ├── 23 # SHA1 of the menu.txt and recipes/apple_pie.txt │ └── 991897e13e47ed0adb91a0082c31c82fe0cbe5 ├── 40 # SHA1 of the README.txt file │ └── fd423f20087b88abfe1d0938b3eb1b60203063 ├── ac # The SHA1 of the commit itself │ └── c3790dd4196ddb0109da375f44574b36ac42f3 ├── b3 # SHA1 and type of the root folder. │ └── 6957a8fcacfd058efe81cd78d23e1905e8aea4 ├── c7 # SHA1 of the recipes folder │ └── c5f73d3b5f56ed11817709b3a2a7a86379b6a7 ├── info └── pack # Every sub-folders together with the file name blow is a SHA1 # GIT save files this way to limit too much items in one directory 7 directories, 5 files :~/gitdemo1/.git$ git cat-file acc3790dd4196ddb0109da375f44574b36ac42f3 -p tree b36957a8fcacfd058efe81cd78d23e1905e8aea4 # commit includes root folder author Your Name \u003cyou@example.com\u003e 1496600945 -0400 committer Your Name \u003cyou@example.com\u003e 1496600945 -0400 First commit! :~/gitdemo1/.git$ git cat-file acc3790dd4196ddb0109da375f44574b36ac42f3 -t commit # type of the SHA1 is commit Let’s see the content, and type of a directory “recipes”, and content of directory “.” :~/gitdemo1/.git$ git cat-file c7c5f73d3b5f56ed11817709b3a2a7a86379b6a7 -t tree # # type of the SHA1 is tree :~/gitdemo1/.git$ git cat-file c7c5f73d3b5f56ed11817709b3a2a7a86379b6a7 -p 100644 blob 40fd423f2","date":"2023-02-20","objectID":"/git_under_the_hood/:0:0","tags":["coding","git","course"],"title":"git_under_the_hood","uri":"/git_under_the_hood/"},{"categories":null,"content":"Related imports Can be used for less typing, and mobilibility. Not recommanded from .module_name import some_function from ..module_in_parent_folder import another_fuction List attribute names imported via from module import * Without a init py file under compressed folder import star will get every modules \u003e\u003e\u003e from reader.compressed import * # not recommanded way to import \u003e\u003e\u003e locals() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': \u003cclass '_frozen_importlib.BuiltinImporter'\u003e, '__spec__': None, '__annotations__': {}, '__builtins__': \u003cmodule 'builtins' (built-in)\u003e, 'gzipped': \u003cmodule 'reader.compressed.gzipped' from '/home/vma/decmaxn.github.io/py_pkg/reader/compressed/gzipped.py'\u003e, 'bzipped': \u003cmodule 'reader.compressed.bzipped' from '/home/vma/decmaxn.github.io/py_pkg/reader/compressed/bzipped.py'\u003e} \u003e\u003e\u003e bzipped \u003cmodule 'reader.compressed.bzipped' from '/home/vma/decmaxn.github.io/py_pkg/reader/compressed/bzipped.py'\u003e \u003e\u003e\u003e gzipped \u003cmodule 'reader.compressed.gzipped' from '/home/vma/decmaxn.github.io/py_pkg/reader/compressed/gzipped.py'\u003e \u003e\u003e\u003e With this py_pkg/reader/compressed/__init__.py , we show only those functions imported to this compressed subpackage, not the modules. from reader.compressed.bzipped import opener as bz2_opener from reader.compressed.gzipped import opener as gzip_opener __all__ = ['bz2_opener','gzip_opener'] Only functions inside __all__ list are imported by import star. \u003e\u003e\u003e locals() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': \u003cclass '_frozen_importlib.BuiltinImporter'\u003e, '__spec__': None, '__annotations__': {}, '__builtins__': \u003cmodule 'builtins' (built-in)\u003e} \u003e\u003e\u003e from reader.compressed import * \u003e\u003e\u003e locals() {'__name__': '__main__', '__doc__': None, '__package__': None, '__loader__': \u003cclass '_frozen_importlib.BuiltinImporter'\u003e, '__spec__': None, '__annotations__': {}, '__builtins__': \u003cmodule 'builtins' (built-in)\u003e, 'bz2_opener': \u003cfunction open at 0x7fb534c023a0\u003e, 'gzip_opener': \u003cfunction open at 0x7fb534b34550\u003e} Modules bzipped ang gzipped are just hidden, they call still be imported, just not with import star. Namespace Packages special cases when a package is not a folder with init py files, but spread across multiple folders. They are directories with same name located in different paths, which are all put in sys.path. When you importing a foo package, python looks for: foo directory with init py file under it, import if found foo.py file, import if found all foo folders in sys.path, import all founded. $ mkdir -p path1/foo $ mkdir -p path2/foo $ touch path1/foo/m1.py $ touch path2/foo/m2.py \u003e\u003e\u003e import sys \u003e\u003e\u003e sys.path.extend(['path1','path2','path3']) # more pathes in sys.path \u003e\u003e\u003e import foo \u003e\u003e\u003e foo.__path__ # 2 folders imported for the same package _NamespacePath(['/home/vma/decmaxn.github.io/path1/foo', '/home/vma/decmaxn.github.io/path2/foo']) \u003e\u003e\u003e import foo.m1 \u003e\u003e\u003e foo.m1.__file__ # python find right folder where to import the m1 module '/home/vma/decmaxn.github.io/path1/foo/m1.py' \u003e\u003e\u003e import foo.m2 \u003e\u003e\u003e foo.m2.__file__ '/home/vma/decmaxn.github.io/path2/foo/m2.py' It’s used to splitting large packages into multiple parts. There is no init py file, to avoid complex init ordoring problems. ","date":"2023-02-18","objectID":"/python/misc_package_module/:0:0","tags":["coding","python","course"],"title":"Misc_package_module","uri":"/python/misc_package_module/"},{"categories":null,"content":"Executable directory A directory can be executed if there is a __main__.py file. $ ls py_pkg/reader/ __init__.py __pycache__ compressed rdm.py $ python3 py_pkg/reader /usr/bin/python3: can't find '__main__' module in 'py_pkg/reader/compressed/' Note the readeer.py file has been renamed to rdm.py to avoid a circular import issue casued by the package and module sharing the same name. After created ``py_pkg/reader/main.py``` like this: import sys from reader.rdm import Reader r = Reader(sys.argv[1]) try: print(r.read()) finally: r.close() It works like a charm. $ python3 py_pkg/reader test.bz2 Content compressed by bz2 $ python3 py_pkg/reader test.gzip Content compressed by gzip $ python3 py_pkg/reader LICENSE.md Copyright (c) 2023 Victor Ma ... ","date":"2023-02-18","objectID":"/python/misc_package_module/:1:0","tags":["coding","python","course"],"title":"Misc_package_module","uri":"/python/misc_package_module/"},{"categories":null,"content":"Create a folder structure as this: py_pkg/reader/ reader module in reader package, has a class called Reader py_pkg/reader/reader.py # class has three methods: \"init\", \"close\" and \"read\". class Reader: #It takes a parameter \"filename\" which is used to open a file in read mode ('rt') def __init__(self, filename): # assigns the file object to an instance variable called \"f\". self.f = open(filename, 'rt') # close method calls the \"close\" method on the file object stored in the instance variable \"f\". def close(self): self.f.close() # The \"read\" method is used to read the contents of the file opened in the constructor. def read(self): # returns the result of calling the \"read\" method on the file object stored in the instance variable \"f\". return self.f.read() Test it \u003e\u003e\u003e import reader.reader \u003e\u003e\u003e f = reader.reader.Reader('LICENSE.md') \u003e\u003e\u003e f.read() 'Copyright (c) 2023 Victor Ma\\n\\n## Blog Infrastructure...' \u003e\u003e\u003e f.close() After import Reader class into the reader package by py_pkg/reader/__init__.py # from package reader's module reader.py, import Reader class. from reader.reader import Reader # Now Reader class is putting directly under reader package Test it again \u003e\u003e\u003e import reader # imported reader package \u003e\u003e\u003e f= reader.Reader('LICENSE.md') \u003e\u003e\u003e f.read() 'Copyright (c) 2023 Victor Ma\\n\\n## Blog Infrastructure...' \u003e\u003e\u003e f.close() subpackage structure as this: py_pkg/reader/compressed Create a subpackage called compressed and a module gzipped.py import gzip import sys opener = gzip.open # common way to check if the current script is being executed as the main program or if it is being imported as a module in another program. if __name__ == '__main__': # opens a gzip file for writing using the first command-line argument passed to the script (sys.argv[1]) as the file path. f = gzip.open(sys.argv[1], mode='wt') # writes a single string to the file, which is obtained by joining all the command-line arguments starting from the third (sys.argv[2:]) with a space character. f.write(' '.join(sys.argv[2:])) f.close() Test each package, subpackage and module can be importted \u003e\u003e\u003e import reader \u003e\u003e\u003e import reader.reader \u003e\u003e\u003e import reader.compressed \u003e\u003e\u003e import reader.compressed.gzipped Test calling the module directly to create a gzipped file $ python3 -m reader.compressed.gzipped test.gzip Content compressed by gzip $ file test.gzip test.gzip: gzip compressed data, was \"test.gzip\", last modified: Sat Feb 18 20:03:35 2023, max compression, original size modulo 2^32 26 Just for the fun of it, create a bzipped module to handle bz2 file, and test import bz2 import sys opener = bz2.open if __name__ == '__main__': f = bz2.open(sys.argv[1], mode='wt') f.write(' '.join(sys.argv[2:])) f.close() Call the compressed helpper module from Reader class Change the reader module like this: import os # used to get file extension, to decide which compressed moudle to call # import both compressed module together from reader.compressed import gzipped,bzipped # creat a dict to map extension to their opener functions extension_map = { '.gzip': gzipped.opener, '.bz2': bzipped.opener, } # class has three methods: \"init\", \"close\" and \"read\". class Reader: #It takes a parameter \"filename\" which is used to open a file in read mode ('rt') def __init__(self, filename): # get the filename's extension extension = os.path.splitext(filename)[1] # define opener function to choose from the dictrionary # or fall back to the default python built-in fuction \"open\" opener = extension_map.get(extension, open) # assigns the file object to an instance variable called \"f\". self.f = opener(filename, 'rt') Test it out \u003e\u003e\u003e import reader.reader \u003e\u003e\u003e f = reader.Reader('test.gzip') \u003e\u003e\u003e f.read() 'Content compressed by gzip' \u003e\u003e\u003e f.close() \u003e\u003e\u003e f = reader.Reader('test.bz2') \u003e\u003e\u003e f.read() 'Content compressed by bz2' \u003e\u003e\u003e f.close() ","date":"2023-02-18","objectID":"/python/example_of_package_module_structure/:0:0","tags":["coding","python","course"],"title":"Example_of_package_module_structure","uri":"/python/example_of_package_module_structure/"},{"categories":null,"content":"Searching path of packages and modules \u003e\u003e\u003e import sys \u003e\u003e\u003e for i in range(len(sys.path)): ... print(sys.path[i]) ... /usr/lib/python38.zip /usr/lib/python3.8 /usr/lib/python3.8/lib-dynload /home/vma/.local/lib/python3.8/site-packages /usr/local/lib/python3.8/dist-packages /usr/lib/python3/dist-packages Package and Modules There is this example package from one entries of searching path. $ find /usr -name urllib -type d /usr/lib/python3.8/urllib Packages are directories in sys.path contain other packages/modules, at least a module as __init__.py. \u003e\u003e\u003e import urllib \u003e\u003e\u003e type(urllib) # this is shown as module \u003cclass 'module'\u003e \u003e\u003e\u003e import urllib.request # this is also shown as module \u003e\u003e\u003e type(urllib.request) \u003cclass 'module'\u003e \u003e\u003e\u003e urllib.__path__ # but urllib is actually a package(folder) ['/usr/lib/python3.8/urllib'] # Same location you found from bash above \u003e\u003e\u003e urllib.reqeust.__path__ Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AttributeError: module 'urllib' has no attribute 'reqeust' import a module from some where Create yourself a module $ cat not_path/test_module.py def found(): print(\"Python found this module\") Directly modify sys.path to add a path can load this module \u003e\u003e\u003e import test_module Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e ModuleNotFoundError: No module named 'test_module' \u003e\u003e\u003e import sys \u003e\u003e\u003e sys.path.append('not_path') \u003e\u003e\u003e import test_module \u003e\u003e\u003e test_module.found() Python found this module \u003e\u003e\u003e [p for p in sys.path if 'not_path' in p] ['not_path'] another way is $PYTHONPATH environment variable will be added to sys.path when python is started $ echo $PYTHONPATH $ export PYTHONPATH=not_path $ echo $PYTHONPATH not_path $ python3 Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e import sys \u003e\u003e\u003e [p for p in sys.path if 'not_path' in p] ['/home/vma/decmaxn.github.io/not_path'] \u003e\u003e\u003e import test_module \u003e\u003e\u003e test_module.found() # Use a method of the module to prove module is imported properly Python found this module Import a package and module Let me move the module inside package $ mv not_path/test_module.py not_path/package/ You have to import the module with a package name now, and you have to call it with the package name. \u003e\u003e\u003e import package # Import package alone \u003e\u003e\u003e package.test_module.found() # won't includes it's modules yet Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AttributeError: module 'package' has no attribute 'test_module' \u003e\u003e\u003e import package.test_module # specifically import the module ... \u003e\u003e\u003e package.test_module.found() # makes it work Python found this module \u003e\u003e\u003e test_module.found() # Can't call module name alone yet Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e NameError: name 'test_module' is not defined \u003e\u003e\u003e Note importing the package won’t include it’s modules above. Import package will run __init__.py under it. $ echo \"print('package is being imported')\" \u003e not_path/package/__init__.py $ ls not_path/package/ __init__.py __init__.py is run when package is imported \u003e\u003e\u003e import package package is being imported \u003e\u003e\u003e package.__file__ '/home/vma/decmaxn.github.io/not_path/package/__init__.py' This can be used to avoid importing each modules in the package one by one $ echo \"from package.test_module import found as fd\" \u003e\u003e not_path/package/__init__.py Let’s import the method of a moudle directly, bypassing the module, to the package. \u003e\u003e\u003e import package package is being imported \u003e\u003e\u003e package.fd() # The as name of found method is attached directly to the package Python found this module This way can be used to simplify long pathes of package/module… ","date":"2023-02-17","objectID":"/python/package_module_path/:0:0","tags":["coding","python","course"],"title":"Package_module_path","uri":"/python/package_module_path/"},{"categories":null,"content":"What is generator Generators are a powerful tool in Python that allow you to create iterable objects on-the-fly. They are functions that use the yield statement instead of return to produce a sequence of values. Why we need generator One of the main reasons why we need generators is that they are memory-efficient. When you create a list, for example, all the elements of the list are created and stored in memory at once. If the list is very large, this can consume a lot of memory. Generators, on the other hand, only generate one value at a time as you iterate over them, so they don’t require as much memory. How generator works Generators can also be more efficient in terms of computation time. Since they generate values on-the-fly, they can often avoid unnecessary calculations and terminate early if the result is already determined. \u003e\u003e\u003e def need_return(init_value): ... tmp = init_value ... for item in range(300): ... if item == tmp: # since item eq tmp, ... tmp *= 2 # double tmp makes tmp always bigger than item ... print(\"yeild a qualified item=%dfrom inside the generator\" % item) ... yield item # Control goes out to caller ... print(\"control back to the generator\") ... \u003e\u003e\u003e for i in need_return(10): ... print(\"Outside caller received item=%d\\n\" % i) ... yeild a qualified item=10 from inside the generator Outside caller received item=10 control back to the generator yeild a qualified item=20 from inside the generator Outside caller received item=20 control back to the generator yeild a qualified item=40 from inside the generator Outside caller received item=40 control back to the generator yeild a qualified item=80 from inside the generator Outside caller received item=80 control back to the generator yeild a qualified item=160 from inside the generator Outside caller received item=160 control back to the generator __iter__ and __next__ methods When the Python interpreter encounters the yield keyword in a generator function, it automatically converts the generator function to a generator object and adds the iter() and next() methods to the object. The implementation of these methods is generated automatically by the Python interpreter and includes the necessary logic to control the generator’s iteration and state. ","date":"2023-02-16","objectID":"/python/generator/:0:0","tags":["coding","python","tips"],"title":"Generator","uri":"/python/generator/"},{"categories":null,"content":"Start another ECS task for service before stop the original task I have made an improvement to my stop ecs task Lambda function that manages my ECS service in a more graceful manner. Previously, it would stop the task associated with my ECS service to trigger a service refresh. This would result in the service being offline for a few minutes. With this improvement, it now increases the task count to 2, effectively launching a new task. This new task runs in parallel with the existing task, ensuring that there is no downtime for my ECS service. Once the new task is confirmed as stable, it then proceeds to stop the old task. By doing this, my ECS service remains available throughout the entire update process, as the new task is already running and handling requests before the old task is stopped. This ensures a smooth and uninterrupted user experience, as my service is always available. import boto3 import os import time # The handler function is triggered when the AWS Lambda function is executed. def handler(event, context): # This app change desired number to 2 and wait for it stable, then change it back after kill old runing tasks # The boto3 library is imported and the 'ecs' client is created using boto3.client(). client = boto3.client('ecs') # The cluster_name and service_name are read from environment variables 'CLUSTER_NAME' and 'SERVICE_NAME'. cluster_name = os.environ['CLUSTER_NAME'] service_name = os.environ['SERVICE_NAME'] print(f\"Cluster name: {cluster_name}\") print(f\"Service name: {service_name}\") # A helper function \"stoptask\" is defined that takes in a task ID and a reason for stopping the task. def stoptask(task_id, reason): # This function stops the task by calling the 'stop_task' method of the ECS client, passing the cluster_name, task ID, and reason for stopping the task. resp = client.stop_task( cluster=cluster_name, task=task_id, reason= \"Daily refresh\" ) print(f\"Task ID: {task_id}\") print(f\"Response from stop_task: {resp}\") return resp # A helper function to use 'list_tasks' method of the ECS client is called to retrieve a list of all running tasks for the specified service in the cluster. def listtasks(): response = client.list_tasks( cluster=cluster_name, desiredStatus='RUNNING', serviceName=service_name, launchType='FARGATE' ) tasks = response[\"taskArns\"] print(f\"Running tasks: {tasks}\") return tasks # A helper function to change the desired number def desiredcount(new_desired_count): response = client.update_service( cluster=cluster_name, service=service_name, desiredCount=new_desired_count ) print(f\"Updated Service {service_name} to have {new_desired_count} desired numbers\") # A helper function to Wait for service to be stable def wait_service_stable(): max_attempts = 36 # set a maximum number of attempts to prevent an infinite loop attempts = 0 while True: describe_response = client.describe_services( cluster=cluster_name, services=[service_name] ) service = describe_response['services'][0] running_count = service['runningCount'] desired_count = service['desiredCount'] # print(f\"Running tasks: {running_count}/{desired_count}\") if running_count == desired_count: print(f\"Service {service_name} now has {running_count} running tasks\") break attempts += 1 if attempts \u003e= max_attempts: print(f\"Service {service_name} did not become stable within {max_attempts} attempts\") break time.sleep(10) # Increase desired number to 2 and wait for it become stable tasks = listtasks() desiredcount(2) wait_service_stable() # A for loop iterates over the task IDs and calls the stoptask function, passing in the task ID and a reason for stopping the task. The response from the stoptask function is printed. for task in tasks: stoptask(task,\"Daily refresh\") print(f\"Stopped the originally running task {task}\") # Decrease desired number back to 1 and wait for it become stable desiredcount(1) wait_service_stable() listtasks() functions stoptask, listtasks, desiredcount and wait_service_stable have all been used more than once. ","date":"2023-02-15","objectID":"/swap_ecs_task_in_service/:0:0","tags":["coding","python","boto3"],"title":"Swap_ecs_task_in_service","uri":"/swap_ecs_task_in_service/"},{"categories":null,"content":"In Python, the copy() method of a list creates a shallow copy of the list, which means that it creates a new list with a new memory address, but the new list contains references to the same objects as the original list. This means that changes made to the objects in the new list will also affect the objects in the original list, and vice versa. \u003e\u003e\u003e original_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \u003e\u003e\u003e new_list = original_list.copy() \u003e\u003e\u003e new_list[0][0] = 10 \u003e\u003e\u003e print(original_list) [[10, 2, 3], [4, 5, 6], [7, 8, 9]] \u003e\u003e\u003e print(new_list) [[10, 2, 3], [4, 5, 6], [7, 8, 9]] As you can see, the modification to the first element of new_list also affects the corresponding element in the original_list. This is because both lists contain references to the same nested list object. If you need to create a new list that is independent of the original list, you can use the copy.deepcopy() method of the copy module, as shown below: \u003e\u003e\u003e import copy \u003e\u003e\u003e original_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \u003e\u003e\u003e new_list = copy.deepcopy(original_list) \u003e\u003e\u003e new_list[0][0] = 10 \u003e\u003e\u003e print(original_list) [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \u003e\u003e\u003e print(new_list) [[10, 2, 3], [4, 5, 6], [7, 8, 9]] The reason for having both shallow and deep copies is that they are useful in different situations. Shallow copies are faster to create and use less memory, which makes them a good choice when you want to create a copy of an object that you don’t intend to modify. Deep copies, on the other hand, are slower to create and use more memory, but they create an independent copy of the object, which is important when you want to modify the copy without affecting the original object. In general, you should use a shallow copy when you only need to create a new object that is a copy of the original, and you don’t intend to modify it. If you need to modify the copy without affecting the original, or if the original object contains nested objects that you want to copy as well, you should use a deep copy. In Python,a copy is automatically deep when it involves immutable objects such as numbers, strings, and tuples. Immutable objects cannot be changed once they are created, so there is no need to create a new copy of them when they are used in a new object. ","date":"2023-02-14","objectID":"/python/shadow_and_deep_copy/:0:0","tags":["coding","python","tips"],"title":"Shadow_and_deep_copy","uri":"/python/shadow_and_deep_copy/"},{"categories":null,"content":"one liner for loop Instead of: \u003e\u003e\u003e m = [] \u003e\u003e\u003e for i in range(10): ... m.append(i) ... \u003e\u003e\u003e m [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] do \u003e\u003e\u003e [i for i in range(10)] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u003e\u003e\u003e {\"index\"+str(i): i*2 for i in range(3)} {'index0': 0, 'index1': 2, 'index2': 4} one liner condition Instead of: \u003e\u003e\u003e done = False \u003e\u003e\u003e if done: ... a =1 ... else: ... a =2 ... \u003e\u003e\u003e a 2 do \u003e\u003e\u003e a = 1 if done else 2 \u003e\u003e\u003e a 2 one liner condition plus for loop Instead of: \u003e\u003e\u003e l = [] \u003e\u003e\u003e for i in range(10): ... if i%2 == 0: ... l.append(i*2) ... \u003e\u003e\u003e l [0, 4, 8, 12, 16] do \u003e\u003e\u003e [i*2 for i in range(10) if i%2 ==0] [0, 4, 8, 12, 16] \u003e\u003e {\"index\"+str(i): i*2 for i in range(10) if i%2 ==0} {'index0': 0, 'index2': 4, 'index4': 8, 'index6': 12, 'index8': 16} enumerate automatically for indexing Instead of: \u003e\u003e\u003e count = 0 \u003e\u003e\u003e l = [1,2,3,4] \u003e\u003e\u003e for data in l: ... if count == 2: ... data += 1 ... l[count]=data ... count += 1 ... \u003e\u003e\u003e l [1, 2, 4, 4] do \u003e\u003e\u003e l = [1,2,3,4] \u003e\u003e\u003e for index, data in enumerate(l): ... if index == 2: ... data += 1 ... l[index] = data ... \u003e\u003e\u003e l [1, 2, 4, 4] Zip to loop together Instead of: \u003e\u003e\u003e name = [\"a\", \"b\", \"c\"] \u003e\u003e\u003e number = [1,2,3] \u003e\u003e\u003e d = [] \u003e\u003e\u003e d= {} \u003e\u003e\u003e for i in range(3): ... d[name[i]] = number[i] ... \u003e\u003e\u003e d {'a': 1, 'b': 2, 'c': 3} do \u003e\u003e\u003e for n, b in zip(name, number): ... d[n] = b ... \u003e\u003e\u003e d {'a': 1, 'b': 2, 'c': 3} reverse \u0026 reversed Instead of \u003e\u003e\u003e number [1, 2, 3] \u003e\u003e\u003e _number = [] \u003e\u003e\u003e for i in range(len(number)): ... _number.append(number[-1-i]) ... \u003e\u003e\u003e _number [3, 2, 1] do \u003e\u003e\u003e _number [3, 2, 1] \u003e\u003e\u003e [_number[-1-i] for i in range(len(_number))] [1, 2, 3] or \u003e\u003e\u003e _number [1, 2, 3] \u003e\u003e\u003e _number.reverse() \u003e\u003e\u003e _number [3, 2, 1] or \u003e\u003e\u003e _number [1, 2, 3] \u003e\u003e\u003e [i for i in reversed(_number)] [3, 2, 1] slice operator The slice operator in Python is a powerful feature that allows you to extract a range of elements from a sequence (such as a list, tuple or string). The syntax for the slice operator is [start:stop:step], where start is the index of the first element to be included, stop is the index of the first element to be excluded, and step is the distance between each element to be included. \u003e\u003e\u003e number [1, 2, 3] \u003e\u003e\u003e number[::-1] [3, 2, 1] If start is not specified, it defaults to 0, and if stop is not specified, it defaults to the length of the sequence. If step is not specified, it defaults to 1. By using a negative value for step, you can extract elements from the sequence in reverse order. Using the slice operator, you can easily manipulate and extract data from sequences without the need for more complex loops and conditional statements. ","date":"2023-02-13","objectID":"/python/concise_form/:0:0","tags":["coding","python","tips"],"title":"Concise_form","uri":"/python/concise_form/"},{"categories":null,"content":"Interact with AWS resource with boto3 This is used in an AWS Lambda been triggered daily to do a maintenance task. The infrastructure part is done by SAM. import boto3 import os # The handler function is triggered when the AWS Lambda function is executed. def handler(event, context): # This app stops all running tasks of an ECS cluster and service. # The boto3 library is imported and the 'ecs' client is created using boto3.client(). client = boto3.client('ecs') # The cluster_name and service_name are read from environment variables 'CLUSTER_NAME' and 'SERVICE_NAME'. cluster_name = os.environ['CLUSTER_NAME'] service_name = os.environ['SERVICE_NAME'] print(f\"Cluster name: {cluster_name}\") print(f\"Service name: {service_name}\") # A helper function \"stoptask\" is defined that takes in a task ID and a reason for stopping the task. def stoptask(task_id, reason): # This function stops the task by calling the 'stop_task' method of the ECS client, passing the cluster_name, task ID, and reason for stopping the task. resp = client.stop_task( cluster=cluster_name, task=task_id, reason= \"Daily refresh\" ) print(f\"Task ID: {task_id}\") print(f\"Response from stop_task: {resp}\") return resp # The 'list_tasks' method of the ECS client is called to retrieve a list of all running tasks for the specified service in the cluster. response = client.list_tasks( cluster=cluster_name, desiredStatus='RUNNING', serviceName=service_name, launchType='FARGATE' ) tasks = response[\"taskArns\"] print(f\"Running tasks: {tasks}\") # A for loop iterates over the task IDs and calls the stoptask function, passing in the task ID and a reason for stopping the task. The response from the stoptask function is printed. for task in tasks: resp = stoptask(task,\"Daily refresh\") print(f\"Stopping task: {resp}\") ","date":"2023-02-13","objectID":"/stop_ecs_task/:0:0","tags":["coding","python","boto3"],"title":"Stop_ecs_task","uri":"/stop_ecs_task/"},{"categories":null,"content":"Exception Mechanism for interrupting normal program flow and continuing in surrounding context. event is raising an exception handling an exception with exception handler unhandled exceptions cause termination Exception objects transferred from event to handler Exception are ubiquitous in Python compare with other programing languages. exceptional.py with unhandled exception DIGIT_MAP = { 'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', } def convert(s): number = '' for token in s: number += DIGIT_MAP[token] x = int(number) return x Now let’s make a good call and an exception \u003e\u003e\u003e from exceptional import convert \u003e\u003e\u003e convert(\"one three two\".split()) 132 \u003e\u003e\u003e convert(\"seventeen\".split()) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"/home/vma/decmaxn.github.io/exceptional.py\", line 17, in convert number += DIGIT_MAP[token] KeyError: 'seventeen' Handle KeyError and TypeError with error code def convert(s): try: number = '' for token in s: number += DIGIT_MAP[token] # Exception is raised x = int(number) # Skipped when exception is raised print(f\"Conversion succeeded! x = {x}\") # Skipped when exception is raised except KeyError: # Program jumped to here when this exception is raised print(\"Conversion failed!\") x = -1 except TypeError: # Program jumped to here when this exception is raised print(\"Conversion failed!\") x = -1 return x test \u003e\u003e\u003e from exceptional import convert \u003e\u003e\u003e convert(\"one two three\".split()) Conversion succeeded! x = 123 123 \u003e\u003e\u003e convert(\"seventeen\".split()) Conversion failed! -1 \u003e\u003e\u003e convert(123) Conversion failed! -1 Programmer Errors Programmer Errors should not be caught at runtime, etc. IndentationError, SyntaxError and NameError def convert(s): \"\"\"Convert a string to an integer.\"\"\" x = -1 try: number = '' for token in s: number += DIGIT_MAP[token] x = int(number) except (KeyError, TypeError): # empty block is not permitted and can be solved by adding pass statement as no-op return x Accessing Exception Objects import sys DIGIT_MAP = . . . def convert(s): try: number = '' for token in s: number += DIGIT_MAP[token] return int(number) except (KeyError, TypeError) as e: # Use as keyword print(f\"Conversion error: {e!r}\", #Print error message file=sys.stderr) return -1 Test \u003e\u003e\u003e from exceptional import convert \u003e\u003e\u003e convert(\"seventeen\".split()) Conversion error: KeyError('seventeen') -1 \u003e\u003e\u003e convert(123) Conversion error: TypeError(\"'int' object is not iterable\") -1 Re-raising Exceptions and clean up action Much better and altogether more Pythonic is to forget about error return codes completely and go back to raising an exception from convert. Instead of returning an un‑Pythonic error code, we can simply omit our error message and re‑raise the exception object we’re currently handling. This can be done by replacing the return a ‑1 with raise at the end of our exception handling block. Without a parameter, raise simply re‑raises the exception that is being currently handled. import os import sys def make_at(path, dir_name): original_path = os.getcwd() os.chdir(path) try: os.mkdir(dir_name) except OSError as e: print(e, file=sys.stderr) raise # Re-raise exception so errors are not passed silently finally: # Clean up action no matter mkdir works or not os.chdir(original_path) # try-block terminates ","date":"2023-02-12","objectID":"/python/exception/:0:0","tags":["coding","python","course"],"title":"Exception","uri":"/python/exception/"},{"categories":null,"content":"Simple function def greeting(name): # order matters, define first print(\"Hello\", name) #main program input_name = input(\"Enter your name:\\n\") greeting(input_name) Scope The input_name is a global var and has global scope, # name is not defined - cause it's defined and only avaible in the func # print(\"Thanks\", name) print(\"Thanks\", input_name) # input_name is defined outside of func This greeting_global function uses a global var def greeting_global(): # define func without var print(\"Hello again\", input_name) # refer to a global var greeting_global() Return and main func to orginzing def greeting_return(): return \"Retruned? Hello, \" + input_name # Return a value instead def main(): # main func to orgnize the code retruned = greeting_return() print(retruned) main() Examle import random def roll_dice(): dice_total = random.randint(1,6) + random.randint(1,6) # maybe 1,12 is ok too return dice_total #main program def main(): player1 = input(\"Enter player 1 name:\\n\") player2 = input(\"Enter player 2 name:\\n\") roll1= roll_dice() roll2= roll_dice() print(player1, \" rolled\", roll1) print(player2, \" rolled\", roll2) if roll1 \u003e roll2: print(player1, 'wins') elif roll1 \u003c roll2: print(player2, 'wins') else: print('tie') main() organize Weather program Reference ","date":"2023-02-12","objectID":"/python/function/:0:0","tags":["coding","python","course"],"title":"Function","uri":"/python/function/"},{"categories":null,"content":"Venv Creating virtual env, make sure to slect vscode python interpreter after. $ python3 -m venv venv $ source venv/bin/activate (venv) $ pip3 install requests $ deactivate Api call example First sign up at Open weather and get an API key. import requests # Copy/paste from Open weatcher:\"https://api.openweathermap.org/data/2.5/weather?lat={lat}\u0026lon={lon}\u0026appid={API key}\" api_key = \"\u003ctobereplacedc\u003e\" city = \"Beverly Hills\" lat = \"34.0901\" lon = \"-118.4065\" def get_weather(lat,lon,api_key): url = \"https://api.openweathermap.org/data/2.5/weather?lat=\"+lat+\"\u0026lon=\"+lon+\"\u0026appid=\"+api_key+\"\u0026units=metric\" response = requests.get(url) json = response.json() # multiple levels of get method description = json.get(\"weather\")[0].get(\"description\") temp_min = json.get(\"main\").get(\"temp_min\") temp_max = json.get(\"main\").get(\"temp_max\") return { 'description': description, 'temp_min': temp_min, 'temp_max': temp_max } def main(): weather = get_weather(lat,lon,api_key) print(\"Today's weather is \", weather.get('description')) print(\"temperature high at:\", weather.get('temp_max'),\"low at:\", weather.get('temp_min')) main() ","date":"2023-02-12","objectID":"/python/venv_and_api/:0:0","tags":["coding","python","course"],"title":"Venv and API call","uri":"/python/venv_and_api/"},{"categories":null,"content":"Two loop variables in one loop with items method of dictionary This way, you can get both the key and value of each key value pair at the same time Chars = { 'letters': 'abcde...', 'numbers': 1234567890, 'special': '!@#$%...' } for key, value in Chars.items(): # items method of dictionary print(key,'includes',value) Dictionary represent object contacts = { # use dictionary for object \"number\": 4, \"students\": [ #List of dictionaries {\"name\":\"Sarah\", \"email\":\"sarah@email.com\"}, {\"name\":\"Harry\", \"email\":\"harry@email.com\"}, {\"name\":\"Hermione\", \"email\":\"hermione@email.com\"}, {\"name\":\"Ron\", \"email\":\"ron@email.com\"} ] } for student in contacts.get('students'): # student represents each item in students list print(student.get('email')) JSON - Javascript Object Notation some api website return raw data in json format instead of html file. import requests response = requests.get('http://api.open-notify.org/astros.json') # print(response) Response [200] json = response.json() # requests module's json method # print(json) the whole json response for person in json['people']: print(person['name']) ","date":"2023-02-12","objectID":"/python/loop_list_and_dictionary/:0:0","tags":["coding","python","course"],"title":"Loop_list_and_dictionary","uri":"/python/loop_list_and_dictionary/"},{"categories":null,"content":"Compare with javascript object In Python, dictionaries are data structures that store key-value pairs. Each key maps to a unique value within the dictionary, and you can use the keys to look up the corresponding values. For example: person = {'name': 'John', 'age': 32, 'city': 'New York'} print(person['name']) # Output: John In JavaScript, objects serve a similar purpose as dictionaries in Python. They also store key-value pairs, and you can use the keys to look up the corresponding values. For example: const person = {name: 'John', age: 32, city: 'New York'}; console.log(person.name); // Output: John However, their ways to refer to items different as shown above. Similarly, lists in Python and arrays in JavaScript are similar. Dictionary acronyms = { 'LOL': 'laugh out loud', 'IDK': \"I dont' know\", # note the different quotes to avoid problem 'TBH': 'to be honest' } print(acronyms) print(acronyms['IDK']) # Refer to one item acronyms['TBH'] = \"honestly\" #Update an item print(acronyms['TBH']) # print(acronyms['BTW']) KeyError: 'BTW' when there is no such a key print(acronyms.get('BTW')) # Get None if the key doesn't exist acronyms['BTW'] = \"by the way\" # Add an item if it's not exist print(acronyms['BTW']) del acronyms['LOL'] # Delete None Type None is a type that represents the absence of a value, it also evaluates to False if acronyms.get('BTW'): # Use what None type evaluates to for condition print(acronyms.get('BTW')) else: print(\"key BTW is not there\") if acronyms.get('LOL') != None: # Use None type itself to compare print(acronyms.get('LOL')) else: print(\"key LOL is not there\") ","date":"2023-02-11","objectID":"/python/dictionary/:0:0","tags":["coding","python","course"],"title":"Dictionary","uri":"/python/dictionary/"},{"categories":null,"content":"Lists and Loop empty_list = [] print(empty_list) str_list = [\"hello\",\"world\",\"4.5\"] print(str_list) print(\"The first item of str_list is \" + str(str_list[0])) # Refer to a item in the list mixed_list=[\"hello\",100,4.5] print(mixed_list) mixed_list.append(\"AppendedItem\") # Append method print(mixed_list) if \"AppendedItem\" in mixed_list: mixed_list.remove(\"AppendedItem\") # Remove method print(\"AppendedItem is exist and removed\") print(mixed_list) del mixed_list[0] # Use del if you want to use the sequence number print(mixed_list) list_list = [empty_list,str_list,mixed_list] print(list_list) for x in list_list: print(x) Range expenses = [] total = 0 num_expenses = int(input(\"Enter nubmer of expenses:\\n\")) for i in range(num_expenses): expenses.append(float(input(\"How much is expense #\" + str(i) + \":\"))) total = sum(expenses) print(\"You have spent totally $\" + str(total)) Loan caculator # What is the annual percentage rate?\\n apr = float(input(\"What is the annual percentage rate?\\n\")) #6 # How much do you owe， in dollars?\\n money_owned = float(input(\"How much do you owe， in dollars?\\n\")) #100000 # How much you want to pay each month?\\n payment = float(input(\"How much you want to pay each month?\\n\")) #2000 # How many months do you want to see results for?\\n months = int(input(\"How many months do you want to see results for?\\n\")) #58 # convert apr to monthly rate monthly_rate = apr/100/12 for i in range(months): # Add in interest interest_paid = money_owned*monthly_rate money_owned = money_owned+interest_paid # Make a payment if money_owned \u003c payment: # Result after the last payment print(\"You have paid off in \",i+1,\" monthes and the last payment is $\",money_owned,sep=\"\") money_owned = 0 break else: money_owned = money_owned-payment # Result after payment print(\"Interest paid $\",interest_paid,\"Now you owe $\",money_owned,sep=\"\") ","date":"2023-02-10","objectID":"/python/list_and_loops/:0:0","tags":["coding","python","course"],"title":"List_and_loops","uri":"/python/list_and_loops/"},{"categories":null,"content":"Install Python and Hello world Make sure you have it installed $ python3 --version Python 3.8.10 $ python3 Python 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e $ cat hello_world.py print(\"Hello world!\") $ python3 hello_world.py Hello world! extension for vscode After installed ms-python.python vscode extention and select Python interpreter（I never know that I have python2 pre-installed too), I can now click on run button to run the .py file like the one created above. Using Interpreter You know need print to see the output here \u003e\u003e\u003e length=2 \u003e\u003e\u003e width=5 \u003e\u003e\u003e area = length*width \u003e\u003e\u003e area 10 \u003e\u003e\u003e Basic data types and functions Built-in types are installed together with Python: Order Change Duplicate define List ordered changeable Allows [] Tuple ordered unchangeable Allows () Set unordered and unindexed unchangeable* No duplicate {} Dictionary ordered** changeable No duplicate {} *Set items are unchangeable, but you can remove and/or add items whenever you like. **As of Python version 3.7, dictionaries are ordered. In Python 3.6 and earlier, dictionaries are unordered. amount = 20 tax = .13 #Remember the primitive Data Types total = amount + amount*tax print(total) # print function will print the argument print(int(22.6)) # int function convert float to int print(float(10)) # float function convert int to float blog_name = \"Victor's blog\" #Using single quotes or double quotes to identify str print(blog_name) # print out doesn't have quotes becasue it's only to tell python greeting = \"Welcome to\" print(greeting + \" \" + blog_name) # Concatenate two string, and a space your_blog = input(\"what is your blog name\\n\") #Input function print(greeting + \" \" + your_blog) app convert nubmer to string your_age = input(\"What is your age?\\n\") #43 # decades = your_age/10 TypeError: unsupported operand type(s) for //: 'str' and 'int' # decades = int(your_age)/10 # this operator get a fload or whole number decades = int(your_age)//10 # input result is a str print(decades) years = int(your_age)%10 # Modulus operator print(years) # print(\"You are \"+decades+\"Decades and\"+years+\"years old.\") TypeError: can only concatenate str (not \"int\") to str print(\"You are\",decades,\"Decades and\",years,\"years old.\",sep=\" \") # another way of print ","date":"2023-02-09","objectID":"/python/age_calculator/:0:0","tags":["coding","python","course"],"title":"Simple math caculation","uri":"/python/age_calculator/"},{"categories":null,"content":"Comparators \u003e\u003e\u003e temp = 95 # Assignment \u003e\u003e\u003e temp == 85 # Comparator False \u003e\u003e\u003e temp == 95 True Condition and logical operator temp = int(input(\"What is the temporature?\\n\")) if temp \u003c= 95 and temp \u003e=45: # AND Logical operators print(\"Nice, go outside\") #indented code inside a \"Code block\" print(\"There is 4 spaces before this line insead of a tab\") # Tab or 4 spaces # print(\"There is 2 spaces before this line insead of a tab or 4 spaces\") IndentationError elif temp \u003e 95: print(\"Too hot, stay inside\") else: print(\"Too cold, stay inside\") if temp \u003e 95 or temp \u003c 45: # OR logical opeartor print(\"stay inside\") else: print(\"Go outside\") forcast = \"rain\" if not forcast == \"rain\": # Not logical operator print(\"Go outside\") else: print(\"stay inside\") raining = True # Condition with Boolean Data type VAR if raining: # It's more like plain english print(\"Stay inside, it's raining\") Modules Not only built-in types are installed together with Python, Python standard Library, etc. math, datetime, random, os, also get installed. import random roll = random.randint(1,6) #Return a random integer N such that a \u003c= N \u003c= b. guess = int(input(\"What the computer rolls?\\n\")) if roll == guess: print(\"You have guessed right, computer rolled a \" + str(roll)) else: print(\"You lost, computer rolled a \" + str(roll)) Rock, Paper, Scissors game import random computer = random.choice([\"Rock\",\"Paper\",\"Scissors\"]) # Return a random element from the non-empty sequence seq. you = input(\"What do you play: Rock or Paper or Scissors\\n\") if you == computer: print(\"TIE\") elif you == \"Paper\" and computer == \"Rock\": print(\"WIN\") elif you == \"Rock\" and computer == \"Scissors\": print(\"WIN\") elif you == \"Scissors\" and computer == \"Paper\": print(\"WIN\") else: print(\"LOSE\") ","date":"2023-02-08","objectID":"/python/condition_and_module/:0:0","tags":["coding","python","course"],"title":"Condition_and_module","uri":"/python/condition_and_module/"},{"categories":null,"content":"Welcome to my blog! I am an IT professional with a few decades of experience in the field and tons of thing to learn. CLI, not GUI CLI is the ONLY desktop for IT professionals as it allows for efficient and precise execution of tasks, plus small text documentation without screen shots. Scripting, not documentation Put commands together and copy/paste can be used to automate processes and manage multiple systems at once. Scripting to stack tasks to make large systems and problems manageable like My MDT system DevSecOps Create infrastructure with Cloudformation, Terraform, SAM. Provision with Ansible. Git repos should be the single system of truth for both code and infr, even documents. Programing Kubernetes or Cloud eliminate the requirement of DevOps. It’s time to improve my scripting skills, and deal with error and logic with real programing, eventually everything is code. For HR and Agent: I have accumulated some certificates from different vendors when I was on different roles. Most of them are not relative adn expired, here are recent ones: /* 设置图片容器样式 */ .image-container { width: 100%; /* 宽度设置为100%，保证容器可以充满整个屏幕 */ display: flex; /* 使用flex布局 */ flex-wrap: wrap; /* 允许图片自动换行 */ } /* 设置图片样式 */ .image-container img { width: 25%; /* 宽度设置为25%，使得四幅图片平分一行 */ height: auto; /* 高度自适应 */ box-sizing: border-box; /* 盒模型设置为border-box，使得padding和border不会影响图片大小 */ padding: 1px; /* 图片和图片之间留出一些空白 */ } /* 设置响应式图片样式 */ @media (max-width: 480px) { /* 在窗口宽度小于等于768px时生效 */ .image-container img { width: 50%; /* 宽度设置为50%，使得两幅图片平分一行 */ } } @media (max-width: 240px) { /* 在窗口宽度小于等于480px时生效 */ .image-container img { width: 100%; /* 宽度设置为100%，使得一幅图片占据一行 */ } } ","date":"2023-01-20","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":" This setting alone won't protect you. SkipAdminPassword=YESYou should also include this one. AdminPassword=YourPasswordHowever, there is another way, if you don't want to set all your deployed computer with same password:- When you create the installation TS, one of the step is to set Admin Password.  This admin password will be the local admin password for all deployments with that task sequence. I have so far found it in the following 2 places. There is once I changed the bottom one without change the AutoLogon one, and the TS stopped in the middle, prompting for password. \"Help\" for \"AdministratorPassword\" shows:To configure a blank administrator password, write an empty string in Windows System Image Manager (Windows SIM) by right-clicking on the Value setting, and choose Write Empty String. The built-in administrator account will be enabled with a blank password.It seems OK to set them empty, but when I actually set both of them to \"Empty String\", the TS stopped asking to set it. After I change both of them to the same non-Empty String, it start to work perfectly. ","date":"2017-08-06","objectID":"/mdt-admin-password/:0:0","tags":["MDT","Windows"],"title":"MDT Admin Password ","uri":"/mdt-admin-password/"},{"categories":null,"content":"Instruction to hide itYou can find one instruction for version 6, but not 7.5. Her is how:Go to:Settings   Agents/Plug-ins   Symantec Management Agent   Settings   Symantec Management Agent Settings - Targeted Choose \"User Control\" Tab, and uncheck \"Show client tray icon\". It will disappear on client the next time they update. How to display Altiris Management Agent Settings window from command line C:\\Program Files\\Altiris\\Altiris Agent\\AexAgentActivate.exe ","date":"2017-07-11","objectID":"/hide-altiris-agent-icon-from-end-users-but-not-admins/:0:0","tags":["Altiris"],"title":"Hide Altiris Agent icon from end users, but not admins","uri":"/hide-altiris-agent-icon-from-end-users-but-not-admins/"},{"categories":null,"content":"If one computer is online and get the policy, for example install a program every 1 hour 24x7, even it get offline, it will still install it every 1 hour, till the installation is success. After it successfully finishes, it won't run the installation again and again anymore. However, admin won't be able to see it's success, and the computer will remain in the list of computers without this program, till next time this computer get online and report it's success.  ","date":"2017-07-11","objectID":"/policy-for-offline-computers/:0:0","tags":["Altiris","Deploy"],"title":"Policy for offline computers","uri":"/policy-for-offline-computers/"},{"categories":null,"content":"Here is a really good document to learn about WOL, thanks a lot to Symantec! ","date":"2017-07-11","objectID":"/faq-on-wake-on-lan-wol/:0:0","tags":["Altiris","Deploy","PXE","OS"],"title":"FAQ on Wake-On-Lan (WOL)","uri":"/faq-on-wake-on-lan-wol/"},{"categories":null,"content":"The problem with these code is, after Server-Gui-Shell, Server-Gui-Mgmt-Infra are uninstalled, the windows will reboot immediately, leaving index.html template deployment failed. vagrant@acs:~/pywinrm$ cat iis.yaml---- hosts: s12  tasks:  - name: Ensure IIS seb service is installed    win_feature:      name: web-server      state: present  - name: Ensure Server GUI is not installed    win_feature:      name: Server-Gui-Shell      state: absent      restart: true  - name: Deploy index.html file    template:      src: iisstart.j2You can put that Windows Feature block to the last of this playbook, or use handlers as below. However neither is best way. vagrant@acs:~/pywinrm$ cat iis.yaml---- hosts: s12  handlers:  - name: Reboot    win_reboot:  tasks:  - name: Ensure IIS seb service is installed    win_feature:      name: web-server      state: present    when: ansible_os_family == \"Windows\"  - name: Ensure Server GUI is not installed    win_feature:      name: Server-Gui-Shell      state: absent    notify:    - Reboot  - name: Deploy index.html file    template:      src: iisstart.j2      dest: c:\\inetpub\\wwwroot\\iisstart.htmHere is the best way according to ansible document:- restart no TrueFalse Restarts the computer automatically when installation is complete, if restarting is required by the roles or features installed.DEPRECATED in Ansible 2.4, as unmanaged reboots cause numerous issues under Ansible. Check the reboot_required return value from this module to determine if a reboot is necessary, and if so, use the win_reboot action to perform it. From \u003chttp://docs.ansible.com/ansible/win_feature_module.html#support\u003e restart_needed DEPRECATED in Ansible 2.4 (refer to C(reboot_required) instead). True when the target server requires a reboot to complete updates (no further updates can be installed until after a reboot) success boolean True reboot_required True when the target server requires a reboot to complete updates (no further updates can be installed until after a reboot) success boolean True From \u003chttp://docs.ansible.com/ansible/win_feature_module.html#support\u003e  ","date":"2017-07-09","objectID":"/win_feature-changes-will-fail-the-tasks-behind-it-and-its-solution/:0:0","tags":["Windows","Ansible"],"title":"Win_feature changes will fail the tasks behind it, and it's solution","uri":"/win_feature-changes-will-fail-the-tasks-behind-it-and-its-solution/"},{"categories":null,"content":" When I turn on 2 factor authentication with gmail,all my devices like Z30 need some reconfiguration. You might get this idea that you need to install Goggle Authenticator APP on your phone,and found that there is no native app available in your Blackberry world or Amazon App Store. However you get around it by sideload android apps. How to use Google two-step authentication on Blackberry 10 ask you to install Gauth. I installed it and then got rid of it, because I found that an application specific password need to be generated for iPhone, Android and of course my Blackberry. Well, I don’t think that’s 2 factor authentication anymore, but that’s officially suggested by Google, I must at least try it. When I did this I found no where to put in this new password - There is no box for you to put it in on my Blackberry！How come there is there is on in Z10 as indicated in BlackBerry Z10, Gmail and 2-Step Authentication? In this post, I found someone also doesn’t have this way to put in password, but it prompts, mine doesn’t! What makes me more worried is I still have access to my emails, calendar and contacts, even I can’t access them from my computer with only my password. Do I really have to delete my Google account from Blackberry and add it back? What if someone try to get my email by steal my phone? It seems I won’t be able stop them by change my gmail password! Why it can still access my gmails, contacts and calendar? because it’s trusted by google for a period of time, I don’t know how long - maybe as long as 30 days. Well, if you do lost your phone, there is a way to make it expire immediately, as shown here by AnimalPak200. Later on I also found Workaround 1 in KB34651，and I did that too. It’s turned out application specific password is not 2 factor authentication, it’s just a walk around on devices can not use 2 factor authentication. For your Z30, you don’t have to use it, as this new phone is able to use 2 factor authentication, just like your computer! Shortly after you made it expire, there will be error messages for email, calendar or contacts, but there is still no prompt for password. At this point, be patient, eventually it will prompt for user name and password. When it prompts, don’t use the application specific password, use the real one. Remember, your Z30 is treated as a computer by Google right now. After password, you need a SMS code, just like on a new computer. After that, you are all set. So, just treat your Z30 as a computer, ignore all other posts online. ","date":"2015-05-06","objectID":"/two-factor-authentication-for-gmail-on-z30-blackberry-10/:0:0","tags":["OA","Security","Mobile"],"title":"Two factor authentication for Gmail on Z30 - Blackberry 10","uri":"/two-factor-authentication-for-gmail-on-z30-blackberry-10/"},{"categories":null,"content":"MDT installed on Windows 7. The problem is quite simple - permission. Solution is to run MDT as Administrator. ","date":"2015-04-03","objectID":"/mdt-unable-to-mount-wim-so-the-update-process-cannot-continue/:0:0","tags":["MDT"],"title":"MDT: unable to mount wim so the update process cannot continue","uri":"/mdt-unable-to-mount-wim-so-the-update-process-cannot-continue/"},{"categories":null,"content":"I knew ESX alone is free. Although I always get “License Expired” warning at the right bottom of my vSphere, as long as I can still use it, I never thought about fix it. Today I rebooted it after enabled a feature, and found I can no longer power up my VMs, due to license issue. I didn’t have a chance to take any screen dump. I followed these two posts from https://communities.vmware.com/message/2305075 and solved this problem, once for all. Thanks for sharing! Once you login to download the product, you are provided with a licence key - see image below.  \"Open vSphere client, then select host icon and open Configuration tab.Under Software list, open Licensed Features and at the upper right corner, click on Edit…Select “Assign a new license key to this host”, then insert your own free license key provided you by VMWare site.“ ","date":"2015-02-16","objectID":"/unable-to-power-on-vms-due-to-expired-esx-license/:0:0","tags":["Vmware","License"],"title":"Unable to power on VMs due to expired ESX license ","uri":"/unable-to-power-on-vms-due-to-expired-esx-license/"},{"categories":null,"content":"I have been struggle for a few days for the above mentioned problem. First I thought it’s the ISO file’s problem, but it failed multiple ISO file for different purpose . Among them ESXi boot ISO files gave consistent error code, I forgot what it is now. I thought about iLO’s KVM problem, connect the real monitor keyboard, failed too. How about firmware? I downloaded HP Service Pack for ProLiant from HP, but booting from this ISO failed too. Then with the ESXi boot error code, I found the following article, and burned a DVD. Boot from it, with iLO KVM, it upgrade all the firmwares, including iLO to version of 2012. After that, problem solve. SUPPORT COMMUNICATION - CUSTOMER ADVISORYDocument ID: c01171266Version: 1Advisory: Booting a ProLiant Server Using Integrated Lights-Out 2 (iLO 2) Virtual Media May Fail to CompleteNOTICE: The information in this document, including products and software versions, is current as of the Release Date. This document is subject to change without notice.Release Date: 2007-09-13Last Updated: 2007-09-13DESCRIPTIONWhen booting a ProLiant server using Integrated Lights-Out 2 (iLO 2) Virtual Media on a network with high traffic, the boot process may progress slowly and then stop. An error message may or may not be displayed. This can occur on servers with a System ROM dated July 2006 through August 2007 because of a short timeout value in the System ROM USB INT13 routine.SCOPEAny ProLiant server with Integrated Lights-Out 2 (iLO 2) and a System ROM version dated July 2006 through August 2007.RESOLUTIONThe timeout value in the System ROM USB INT13 routine will be increased to 30 seconds in all ProLiant System ROM releases dated after August 2007. As the latest ProLiant System ROMs become available, they will be posted on the HP Software \u0026 Drivers Downloads website at the following URL:http://welcome.hp.com/country/us/en/support.html?pageDisplay=driversUntil the updated Systems ROMs become available, avoid booting a ProLiant server using Integrated Lights-Out 2 (iLO 2) Virtual Media on a network with high traffic.RECEIVE PROACTIVE UPDATES: Receive support alerts (such as Customer Advisories), as well as updates on drivers, software, firmware, and customer replaceable components, proactively via e-mail through HP Subscriber’s Choice. Sign up for Subscriber’s Choice at the following URL: http://www.hp.com/go/myadvisorySEARCH TIP: For hints on locating similar documents on HP.com, refer to the Search Tips document: http://h20000.www2.hp.com/bizsupport/TechSupport/Document.jsp?objectID=c00638154. To search for additional advisories related to Integrated Lights-Out 2 (iLO 2), use the following search string: +Advisory +ProLiant +\"iLO 2\"KEYWORDS: iLO2, halt, fail, stop, hang, freeze Hardware Platforms Affected: HP ProLiant DL580 G5 Server series, HP ProLiant DL385 G2 Server series, HP ProLiant DL365 Server series, HP ProLiant BL465c Server series, HP ProLiant ML310 G3 Server series, HP ProLiant DL320 G4 Server series, HP ProLiant BL680c G5 Server series, HP ProLiant BL480c Server series, HP ProLiant ML310 G3 Storage Server, HP Integrated Lights-Out 2 (iLO 2) Firmware(Standard HP Product), HP ProLiant BL25p G2 Server series, HP ProLiant ML350 G5 Storage Server, HP ProLiant BL20p G4 Server series, HP ProLiant DL380 G5 Server series, HP ProLiant DL585 G2 Storage Server, HP ProLiant DL380 G5 Data Protection Storage Server, HP ProLiant BL45p G2 Server series, HP ProLiant ML310 G4 Server series, HP ProLiant BL460c Server series, HP ProLiant ML310 G4 Storage Server, HP ProLiant DL320s Server series, HP ProLiant ML570 G4 Server series, HP ProLiant DL320s Storage Server, HP ProLiant ML350 G5 Server series, HP ProLiant DL360 G5 Server series, HP ProLiant ML370 G5 Server series, HP Integrated Lights-Out 2 (iLO 2) Standard Blade Edition Firmware(Standard HP Product), HP ProLiant DL380 G5 Storage Server, HP ProLiant DL585 G2 Server series, HP ProLiant DL320 G5 Server series, HP ProLiant BL685c Server series, HP ProLiant D","date":"2014-07-11","objectID":"/ilo2-boot-from-virtual-media-failed-almost-all-the-time/:0:0","tags":["HP","iLo"],"title":"iLo2: Boot from Virtual Media failed almost all the time","uri":"/ilo2-boot-from-virtual-media-failed-almost-all-the-time/"},{"categories":null,"content":"This happened when I try to change some BIOS configuration, struggled for a while, and find this configuring ESXi with iLO 2 on bl490c - up/down arrow don't work.Thanks to the poster for the simple solution:  Works with the Java-version, but not in the IRC.Some one mentioned turn off IE protection mode also could solve the problem, but I didn't bother to try it.  ","date":"2014-07-11","objectID":"/ilo2-up-down-arrow-key-doesnt-work-for-hp-proliant-dl360-g5/:0:0","tags":["HP","iLo"],"title":"iLo2: up / down arrow key doesn't work for HP Proliant DL360 G5","uri":"/ilo2-up-down-arrow-key-doesnt-work-for-hp-proliant-dl360-g5/"},{"categories":null,"content":" Normal 0 false false false EN-US X-NONE X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\",\"serif\";} Microsoft suggest to install 32bit instead of 64bit. Refer to64-bit editions of Office 2013 for details.  64-bit of Office 2013 “As more and more personal computers run 64-bit versions of Windows, it’s tempting to deploy the 64-bit version of Office 2013 to match. One benefit is that 64-bit Office allows users to work with larger sets of Excel and Project data. But, there are compatibility drawbacks for those users because Office add-ins and solutions might not work. That’s why 32-bit Office 2013 is recommended for most users.” Standard system requirements for Office 2013v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false EN-US X-NONE X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\",\"serif\";} Office 2013 32-bit products are supported on the following Windows operating systems:Windows 7 (32-bit or 64-bit)Windows 8 (32-bit or 64-bit)Windows 8.1 (32-bit or 64-bit)Windows Server 2008 R2 (64-bit)*Windows Server 2012 (64-bit)**Office 2013 64-bit products are only supported on the following Windows operating systems:Windows 7 (64-bit)Windows 8 (64-bit)Windows 8.1 (64-bit)Windows Server 2008 R2 (64-bit)*Windows Server 2012 (64-bit)**Microsoft Outlook 2013Be sure to connect Outlook 2013 to the supported versions of Exchange: Exchange 2007, Exchange 2010, or Exchange Server 2013. Outlook 2013 is not supported on Exchange 2003. ","date":"2014-05-26","objectID":"/office-2013-doesnt-support-xp-and-outlook-2013-doesnt-support-exchange-2003./:0:0","tags":["Deploy","Exchange","App"],"title":"Office 2013 doesn't support XP, and Outlook 2013 doesn't support Exchange 2003. ","uri":"/office-2013-doesnt-support-xp-and-outlook-2013-doesnt-support-exchange-2003./"},{"categories":null,"content":"What is Core Edition? It should be made for various \"basic roles\" for windows, like DC and LDAP, File Server and Print Server, DHCP and DNS. It's can not run Microsoft SQL server, or Microsoft Exchange, as they are not basic roles. However it's can run IIS and Hyper-V. Cons for Core EditionI don't mind it can't run MMC locally, but it can't run Internet Explorer or Windows Explorer, which makes it pretty difficult to use. For command line, it doesn't support powershell, which disappointed me again, however the later version of core server, for example 2012, changed it.   First steps to configure Core EditionConfiguring Windows Server 2008 Server Core Basic Networking Settings has some basic command to help you get started. ","date":"2013-06-07","objectID":"/a-little-for-windows-2008-r2-core-edition/:0:0","tags":["Windows","OS"],"title":"A little for Windows 2008 R2 Core Edition","uri":"/a-little-for-windows-2008-r2-core-edition/"},{"categories":null,"content":"Symptoms:User can no longer receive emails from her yahoo groups after she changed her email address. Yahoo group website gives error code for the bounce back, but their support doesn’t reply her for details.  The error code is: Last Bounced Message Remote host said: 501 Syntax error in parameters or arguments [MAIL_FROM] From IMSS’s log, I couldn’t find any record of either passed or whatever. Find Sender Email addressTrend Micro support ask for the sender address, but what user reads xxxx@yahoogroups.ca is not the real sender. I found the real sender by ask user to switch back to their old email address and check the IMSS log for incoming emails. However, you can find it in email header, it like this: Return-Path: sentto-xxxxxxx-xxxxxxx-xxxxxxxx-xxxxxxxxxxxxxxxxxx=xxxxx.xxx.xxx@returns.groups.yahoo.com Root Cause:After found the sender, support find the root cause easily. Refer to this KB.  Root cause is the Email address length. About Email Address length, I found this online, and there seems to have different standards. “There appears to be some confusion over the maximum valid email address size. Most people believe it to be 320 characters (64 characters for the username + 255 characters for the domain + 1 character for the @ symbol). Other sources suggest 129 (64 + 1 + 64) or 384 (128+1+255, assuming the username doubles in length in the future.” Trend Micro support claim they follow an RFC standard limited to 64 characters before the @ symbol. After my user change her email address, the sender address is longer than 64 characters now. Solution:Trend Micro has released a hot fix to disable this checking for version 7.0, and support has confirmed only an extra line in an ini file is needed for version 7.1. Restart a service after that.  C:\\Program Files\\Trend Micro\\IMSS\\config\\tsmtpd.ini CheckSenderLength=0 net stop “Trend Micro IMSS SMTP Service” net start “Trend Micro IMSS SMTP Service” ","date":"2013-06-07","objectID":"/imss-block-yahoo-group-emails-after-email-address-changed/:0:0","tags":["Security","Exchange"],"title":"IMSS Block Yahoo Group emails after email address changed","uri":"/imss-block-yahoo-group-emails-after-email-address-changed/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Symptom:When modify a MSP file, and try to save it. I got the following error. \"Unhandled exception attempting to get file size for the file that doesn't exist\"Cause and Solution:Don’t worry about the version of OS, or if you are opening it from network, the real problem is in this MSP, you are applying a PRF file from a certain location, and the file is not there.  Change the PRF file location to somewhere correct, you will be able to save it.  ","date":"2013-05-09","objectID":"/cant-save-msp-file-with-unhandled-exception-error/:0:0","tags":["Deploy","App"],"title":"Can't save MSP file with Unhandled exception error","uri":"/cant-save-msp-file-with-unhandled-exception-error/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Normal 0 false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Two Windows box in the same network shouldn’t using same SID. But it’s strange that I have never get into a duplicated SID problem by cloning my existing windows VMs and put them into one windows network. I have even developed a list of templates VMs for most of the Windows OS. All I need to do when I need to new machine is to clone the template, they are all from the same a few templates.  For example, Psgetsid shows that all the XP VMs have the same SID, however they are in the same network, and have never give me any problem.             S-1-5-21-725345543-1682526488-1957994488       XP51 CloneS-1-5-21-725345543-1682526488-1957994488       XP51Anyway, recently I run into this problem with cloning a Windows 2003 Server R2 VM. There is no problem to join the domain till I try to login to the domain. Here is the error message. The problem is due to this Windows and AD controller are both clone from the same Windows I created as a template, so they have the same SID. To solve this problem, I used Microsoft’s SysPrep tool, and created a new template, then cloned this template to build a new VM. The problem still exist. I did 2 tests, just made sure I did follow my instruction no wrong.  Obviously the sysprep wasn’t success.To prove it, I found psgetsid.exe tool shows that these 2 boxes from same syspreped image, and the AD controller is also from the same image before sysprep.  S-1-5-21-1623163922-654890622-3203205963       Both system cloned from the syspreped image have the same SIDS-1-5-21-1623163922-654890622-3203205963       Even the AD controller cloned from the image before Sysprep have the same SID. The reason I found is my instruction I found online used sysprep with reseal  and nosidgen option. Refer to sysprep for details of sysprep. ","date":"2013-01-19","objectID":"/problem-of-2-windows-with-same-sid/:0:0","tags":["Deploy","Windows"],"title":"Problem of 2 windows with same SID ","uri":"/problem-of-2-windows-with-same-sid/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-bidi-font-family:\"Times New Roman\";} For the long process of installing Windows Server, I believe most of people like me, we don’t sit there and wait. Recently I was trying to install Windows 2008 R2 on multiple HP Proliant Servers, and on every one of them, every time, the installation stop at this screen shows:\"The computer restarted unexpectedly or encountered an unexpected error. Windows instlation cannot proceed. To install Windows, click \"OK\" to restart the computer, and then restart the installation\"At beginning, I was using SmartStart USB Key and Windows Installation ISO file on network. In days, I tried choosing different option while installing, different RAID configuration, booting with CD, installed on different Proliant Hardware, and end up booting from CD and install from CD. The problem still there. If you are reading this, you might got this problem too. Here is similar story I found online, and his solution worked for me. http://cryptojoe.blogspot.ca/2010/12/windows-server-2008-r2-on-hp-proliant.html ","date":"2013-01-14","objectID":"/windows-installation-failed-on-hp-prolaint-with-blue-screen/:0:0","tags":["HP","Windows","OS"],"title":"Windows installation failed on HP prolaint with blue screen","uri":"/windows-installation-failed-on-hp-prolaint-with-blue-screen/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} http://superuser.com/questions/364978/windows-7-set-default-network-connectionrefers to http://support.microsoft.com/kb/299540http://levynewsnetwork.wordpress.com/2011/12/01/windows-7-default-internet-connection-choice/didn’t try this. Before change the Merit, trace to google.com goes through 192.168.2.11 C:\\\u003eroute printIPv4 Route Table===========================================================================Active Routes:Network Destination        Netmask          Gateway       Interface  Metric          0.0.0.0          0.0.0.0     172.16.184.1   172.16.184.149     25          0.0.0.0          0.0.0.0      192.168.2.1     192.168.2.11     20        127.0.0.0        255.0.0.0         On-link         127.0.0.1    306…..C:\\ \u003etracert www.google.comTracing route to www.google.com[74.125.226.18]over a maximum of 30 hops:  1     4 ms     3 ms     3 ms  192.168.2.1. . . . . .   8   109 ms   121 ms   105 ms  yyz06s05-in-f18.1e100.net [74.125.226.18] After change the Merit, trace to google.com goes through 172.16.184.149  IPv4 Route Table===========================================================================Active Routes:Network Destination        Netmask          Gateway       Interface  Metric          0.0.0.0          0.0.0.0     172.16.184.1   172.16.184.149     25          0.0.0.0          0.0.0.0      192.168.2.1     192.168.2.11     50        127.0.0.0        255.0.0.0         On-link         127.0.0.1    306        127.0.0.1  255.255.255.255         On-link         127.0.0.1    306  127.255.255.255  255.255.255.255         On-link         127.0.0.1    306…..C:\\ \u003etracert www.google.comTracing route to www.google.com[74.125.226.18]over a maximum of 30 hops:  1     5 ms    11 ms     5 ms  172.16.184.252. . . . . . 10     7 ms     8 ms     7 ms  yyz06s05-in-f18.1e100.net [74.125.226.18]Trace complete. ","date":"2012-12-27","objectID":"/change-merit-to-set-the-primary-nic-for-windows-pc-with-multiple-nics/:0:0","tags":["Network","Windows","OS"],"title":"Change Merit to set the primary NIC for Windows PC with multiple NICs","uri":"/change-merit-to-set-the-primary-nic-for-windows-pc-with-multiple-nics/"},{"categories":null,"content":"http://superuser.com/questions/364978/windows-7-set-default-network-connection refers to http://support.microsoft.com/kb/299540 http://levynewsnetwork.wordpress.com/2011/12/01/windows-7-default-internet-connection-choice/ didn’t try this. Before change the Merit, trace to google.com goes through 192.168.2.11 C:\\\u003eroute print IPv4 Route Table =========================================================================== Active Routes: Network Destination Netmask Gateway Interface Metric 0.0.0.0 0.0.0.0 172.16.184.1 172.16.184.149 25 0.0.0.0 0.0.0.0 192.168.2.1 192.168.2.11 20 127.0.0.0 255.0.0.0 On-link 127.0.0.1 306 ….. C:\\ \u003etracert www.google.com Tracing route to www.google.com [74.125.226.18] over a maximum of 30 hops: 1 4 ms 3 ms 3 ms 192.168.2.1 . . . . . . 8 109 ms 121 ms 105 ms yyz06s05-in-f18.1e100.net [74.125.226.18]  After change the Merit, trace to google.com goes through 172.16.184.149 IPv4 Route Table Active Routes: Network Destination Netmask Gateway Interface Metric 0.0.0.0 0.0.0.0 172.16.184.1 172.16.184.149 25 0.0.0.0 0.0.0.0 192.168.2.1 192.168.2.11 50 127.0.0.0 255.0.0.0 On-link 127.0.0.1 306 127.0.0.1 255.255.255.255 On-link 127.0.0.1 306 127.255.255.255 255.255.255.255 On-link 127.0.0.1 306 ….. C:\\ \u003etracert www.google.com Tracing route to www.google.com [74.125.226.18] over a maximum of 30 hops: 1 5 ms 11 ms 5 ms 172.16.184.252 . . . . . . 10 7 ms 8 ms 7 ms yyz06s05-in-f18.1e100.net [74.125.226.18] Trace complete. ","date":"2012-12-27","objectID":"/primary-nic-for-windows/:0:0","tags":null,"title":" Change Merit to set the primary NIC for Windows PC with multiple NICs","uri":"/primary-nic-for-windows/"},{"categories":null,"content":"I need to testing if I can create a big file somewhere, and need a small tool to quickly do it. Refer to this thread . I end up chose RDFC, it works like a charm. Of course, other tools like fsutil works too, but there are some limitations, for example you have to be Administrator to use fstuil, and there is no data created on the hard drive, and I failed to create file on a network share. ","date":"2012-12-24","objectID":"/quickly-create-a-big-file-for-test/:0:0","tags":["Tools"],"title":"Quickly create a big file for test","uri":"/quickly-create-a-big-file-for-test/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} First of all, update take some time, and you can’t use it during the updating. Newer model is faster and you don’t need to worry about the waiting, but be prepared for older model. In BlackBerry Desktop Software, when you use Device -\u003e Update… to check for a possible update, you will get this message. “There are no BlackBerry Device Software updates available”This doesn’t mean there is no update, it just means you have not yet install the Device Software update in this computer. The software update should be downloaded and installed before the update show up. It typically looks like this:9900jAllLang_PBr7.1.0_rel2108_PL5.1.0.546_A7.1.0.746_Rogers_Wireless_Inc.exeDifferent carrier and different model of BB uses different file. You can choose and download it from this website:http://ca.blackberry.com/support/apps-and-software/desktop-and-device-download-sites.htmlAnother way to update the OS is through wireless network. You can do this through Options -\u003e Device -\u003e Software Updates. Typically 30MB file will be downloaded, and wait for you to install.  You can choose to “Install Later” and schedule it, or simply cancel, and you will be prompt that the Update must be completed by certain date or it will be cancelled. You have a month to do so. If you schedule it for midnight when you don’t need to use it, make sure it’s been fully charge. ","date":"2012-12-19","objectID":"/black-berry-device-software-update/:0:0","tags":["Tools","OA"],"title":"Black Berry Device Software Update","uri":"/black-berry-device-software-update/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Microsoft best practices recommend than an Exchange Mail Store does not surpass the 75GB limit. A Typical Exchange server has many Mailbox Store. When you create a mailbox, it’s important to use a store not bigger than 75GB. Here is how to find out the size of each store. Start Exchange System Manager, Browse to the mailbox store you want to check.                 Root -\u003e Administrative Groups -\u003e Location -\u003e Servers -\u003e ServerName -\u003e The Storage Group -\u003e The mailbox Store. Right click the store --\u003e properties --\u003e go to Databased tab Locate the path to the exchaneg databse (edb) file and streaming database (stm) file. The size of both files together is the current mailbox storage size. ","date":"2012-12-12","objectID":"/verify-exchange-mailbox-storage-size/:0:0","tags":["Exchange"],"title":"Verify Exchange Mailbox Storage Size","uri":"/verify-exchange-mailbox-storage-size/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Testing environment:There are 2 connections in the host. One wired directly to internet, and another is wireless go through WebSense, which is blocking websites including YouTube.  Inside a VirtualBox Client with a NAT NIC, by default YouTube is blocked. Follow the instruction from http://www.virtualbox.org/manual/ch09.html#changenatbelow. By default, VirtualBox's NAT engine will route TCP/IP packets through the default interface assigned by the host's TCP/IP stack. (The technical reason for this is that the NAT engine uses sockets for communication.) If, for some reason, you want to change this behavior, you can tell the NAT engine to bind to a particular IP address instead. Use the following command: VBoxManage modifyvm \"VM name\" --natbindip1 \"10.45.0.2\"After this, all outgoing traffic will be sent through the interface with the IP address 10.45.0.2. Please make sure that this interface is up and running prior to this assignment. With my client up and running:C:\\\u003eVboxmanage modifyvm \"S08.64.Download Altiris\" --natbindip1 \"192.168.2.11\"VBoxManage.exe: error: The machine 'S08.64.Download Altiris' is already locked for a session (or being unlocked)VBoxManage.exe: error: Details: code VBOX_E_INVALID_OBJECT_STATE (0x80bb0007), component Machine, interface IMachine, callee IUnknownVBoxManage.exe: error: Context: \"LockMachine(a-\u003esession, LockType_Write)\" at line 419 of file VBoxManageModifyVM.cppShutdown my client, the command works fine. C:\\ \u003eVboxmanage modifyvm \"S08.64.Download Altiris\" --natbindip1 \"192.168.2.11\"Boot my client, the YouTube is still blocked.  Don’t know what’s wrong. I end up using Bridged Adapter as a work around. ","date":"2012-12-03","objectID":"/virtualbox-failed-binding-nat-sockets-to-a-specific-interface/:0:0","tags":["Network","Tools"],"title":"VirtualBox: Failed Binding NAT sockets to a specific interface ","uri":"/virtualbox-failed-binding-nat-sockets-to-a-specific-interface/"},{"categories":null,"content":"Working on this issue for a few days now. Finally identified the problem is on the driver side, not the DHCP or PXE server side - all other computer works just fine. Find online the this thread, and Symantec support also confirmed my finding. It seems Intel has got a support case opened at Nov 8, 2012, Please refer to here, but I can’t wait. Symantec Support suggest to use WinPE, I end up went this way. This problem also have another symptomlike 82579LM - DOS NDIS2-driver does not work - no ping response. ","date":"2012-11-30","objectID":"/elitebook-8570p-can-not-get-ip-from-dhcp-with-ndis-driver/:0:0","tags":["Altiris","Deploy","PXE","OS"],"title":"EliteBook 8570p Can not get IP from DHCP with NDIS driver","uri":"/elitebook-8570p-can-not-get-ip-from-dhcp-with-ndis-driver/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Problem:Symantec Installation Manager prompt for Domain\\User name and password for “Reporsitory: www.solutionsam.com” Reason:It seems like related to something between your server and internet, in my case it’s a webfilter (Websense) that was blocking the download. How it allowed an initial install and blocked it later on is beyond me. I see cases related to proxy server with user name and password. If you are also behind a proxy server, it worth a try to connect it directly to internet. ","date":"2012-11-30","objectID":"/sim-problem-of-downloading/:0:0","tags":["Altiris"],"title":"SIM problem of downloading","uri":"/sim-problem-of-downloading/"},{"categories":null,"content":" They all have this RED ball with Cross on it. For computers, once you rejoin it into the AD, the RED ball with cross disappear. ","date":"2012-11-27","objectID":"/disabled-account-or-removed-computer-in-ad/:0:0","tags":["AD"],"title":"Disabled Account or Removed Computer in AD","uri":"/disabled-account-or-removed-computer-in-ad/"},{"categories":null,"content":"Been a Black Berry user for years, I have never paid attention to this question.Well the answer is yes, but if you do a test, you probably won’t have time to wait for it happen. Emails on BB and your Outlook will sync over air, but not immediately. \"Reconcile Now” will sync two place immediately. So do emails you’ve read on your Black Berry appear read in your Outlook. ","date":"2012-11-19","objectID":"/will-emails-deleted-from-bb-been-deleted-from-outlook-and-vise-versa/:0:0","tags":["OA","Exchange","Mobile"],"title":"Will emails deleted from BB been deleted from Outlook, and vise versa?","uri":"/will-emails-deleted-from-bb-been-deleted-from-outlook-and-vise-versa/"},{"categories":null,"content":"Multiple users called in for their Scan to Email emails have end up in their Junk Box around same time. I found the following document here. Thanks to their sharing!  Filtered by Outlook  If the message has been filtered out by Outlook, then the Infobar will contain the following text; ”This message was marked as spam using the Outlook Junk E-mail filter.” When you see this message, you’ll need to troubleshoot your Junk E-mail settings in Outlook. Make sure you have the latest updates installed and even try turning off the Junk E-mail filter to find out where the messages end up now. Filtered by another scannerIf the message has been filtered out by another scanner, then the Infobar will contain the following text; ”This message was marked as spam using a junk filter other than the Outlook Junk E-mail filter.” When you see this message, you’ll need to troubleshoot the virus scanner or Junk E-mail filter that is included in your Security Suite or contact your ISP or mail administrator and have him/her check the virus scanner and/or Junk E-mail filter settings on the mail server (for instance; adjust the SCL threshold when working with Exchange). Filtered by a rule or moved manually If a message has been filtered out via a rule or has been moved to the Junk E-mail folder manually, then the Infobar will not indicate a reason why the message sits in the Junk E-mail folder. When you see this message, you’ll need to check if you don’t have any rules configured which move messages to the Junk E-mail folder. ","date":"2012-11-15","objectID":"/emails-from-scanner-end-up-in-junk-box-of-multiple-users-around-same-time/:0:0","tags":["OA","Exchange","Outlook"],"title":"Emails from scanner end up in Junk Box of multiple users around same time","uri":"/emails-from-scanner-end-up-in-junk-box-of-multiple-users-around-same-time/"},{"categories":null,"content":"I found this table here, thanks for their contribution! Error CodeCommentsSendingReceiving (Our customers will be informed by people who are trying send e-mail to them).4.3.1Not enough disk space on the delivery server. Microsoft say this NDR maybe reported as out-of-memory error.This indicates that the recipient’s e-mail box is full.If somebody informs you about this error then your mailbox is reaching its limit. You need to either upgrade your space or archive your old e-mails or delete them.4.3.2Classic temporary problem, the Administrator has frozen the queue.If you have sent an e-mail and you got this bounce back then the issue is with the receiving server and not with Apps4Rent Server.Not Applicable for us. We do freeze the queue.4.4.1Intermittent network connection. The server has not yet responded. Classic temporary problem. If it persists, you will also a 5.4.x status code error.This would not happen with Apps4Rent servers. However, if such a situation occurs, then there might be a network issue with the receiving server at the time when our server tried to deliver the e-mail. If this is followed by 5.4.x then please contact our support department with the full header of the e-mail for indepth analysis. If the issue is from our side we will try and fix the issue.If somebody informs you that they are getting this error then the sending server might be having some connectivity issues. Have the sender try again and if it fails then we need the complete headers of the bounceback message. 4.4.6Too many hops. Most likely, the message is looping.Please check if there is a loop formed with the e-mail address. If somebody sent an e-mail to you and has complained to you that you they got the following bounceback then you need to login into your control panel and verify if there is a loop created for the receiving e-mail address at any point. The issue is not from the server side but the way recipients e-mail address has been set.If you get this error while sending an e-mail to someone; then you need to let that person know about this. The e-mail address on the other server is not setup correctly. In either case, the issue is not with the sending server or receiving server. It’s the way e-mail address has been setup.4.4.9A DNS problem. Check your smart host setting on the SMTP connector. For example, check correct SMTP format. Also, use square brackets in the IP address [64.xxx.xxx.xxx] You can get this same NDR error if you have been deleting routing groups.This error will not happen while sending e-mails from our servers.If somebody complaints to you that they got this error while sending e-mail to you; please have the sender contact his administrator as the SmartHost has not been setup in the right manner.4.6.5Multi-language situation. Your server does not have the correct language code page installed.Not Applicable to Apps4Rent Server.Not Applicable to Apps4Rent Server5.1.xProblem with email address.5.1.0Often seen with contacts. Check the recipient address.If you get this bounce back; then please send the complete header to our Support Department.If you get this bounce back; then please send the complete header to our Support Department.5.1.1Another problem with the recipient address. Possibly the user was moved to another server in Active Directory. Maybe an Outlook client replied to a message while offline.You might get this error when an e-mail was added to the system and then removed and re-added. Please type the complete e-mail address rather than selecting the user from GAL or drop down. If you don’t receive a bounce back after you have typed the complete e-mail address then you need delete the e-mail address that you get from the drop down and also download the Offline Address Book againYou might get this error when an e-mail was added to the system and then removed and re-added. Please type the complete e-mail address rather than selecting the user from OAB or drop down. If you don’t receive a bounce back after you ","date":"2012-11-14","objectID":"/useful-error-codes-for-exchange-bounce-back-emails/:0:0","tags":["Exchange"],"title":"Useful error codes for Exchange bounce back emails","uri":"/useful-error-codes-for-exchange-bounce-back-emails/"},{"categories":null,"content":" Found these wonderful thread about this issue here. I just take the question and answer out for you to read easily. Q: Somehow when I starting syncing my new Storm, I ended up with 3 Desktop Contact Lists - all the same, all with the title of “Desktop”. Now when I go to Contacts, I have 3 copies of every entry. Anyone know how I can delete a contact list individually without resetting the unit ? Thanks. A: This is caused when someone moves or re-adds a BB user to the BES without wiping their Blackberry before reactivating. This will create a new contact list each time. To remove it, go to Contacts and click Options. Then type rset, it will pop up with a screen asking if you want to wipe the contacts, select yes through all windows. You can then wirelessly sync or use desktop manager to repopulate contacts. Actually you don’t have to delete all of them, answer yes to the confirmation questions that mentioned “It’s not Sync wirelessly”, that will get rid of the duplicated ones. ","date":"2012-11-10","objectID":"/multiple-desktop-contact-list-on-bb/:0:0","tags":["OA","Mobile"],"title":"Multiple Desktop Contact List on BB","uri":"/multiple-desktop-contact-list-on-bb/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} UPS and ATS can have Network Management Card inserted, and they need a IP address to be assigned before it can be used. APC’s product manual is not perfect, which include some out dated information, plus it's easy to over look the simple HyperTerminal program, I have had some hard time with them. Here are what I learned. There are 4 ways to assign IP address according to APC’s product manual.  I was interested by the ARP way, it looks efficient, but it didn’t work for me with unknown reason. Also I didn’t know where to find the MAC address at beginning, it’s turned out on a supermarket receipt kind of paper taped on the product. Next, I installed the Device IP Configuration Wizard program from a CD come with the product, and started it. I made another mistake by immediately clicked next, and jumped to the next page, and start to be confused.  I should have read on the first page and waited for the device to be picked up. It worked for me later on.    Next, because I wondered how am I find out what IP address is been assigned to, I choosed connct through Serial Port. Later on I realized IP address should be get from DHCP server, because Vendor Class / Client/User Class Identifiers will be sent to DHCP server, and shows up there. With Serial Port, I end up calling APC support, here are mistakes I made. Hyper Terminal is decommissioned on Windows 7, but simply copy hypertrm.exe and hypertrm.dll from a XP box works like a charm. Special Serial Cable should be used, they are come with the product and labeled on the connector. Follow the user manual to make sure you have the right cable. I had a hard time to connect to my ATS even with the correct cable. It’s end up I didn’t pay attention to the port configuration. They are 19200 bps, 8 data bits, no parity, 1 stop bit and no flow control. Note, HyperTerminal come with Hardward Flow control as default. It has to be changed. Sometimes 9600 bps works too, but there is one time I spend a long time to troubleshoot, and it’s end up 19200 bps solved the problem. To configure IP address, you have to use option 11, Web config. They renamed it to something like NMW config, but it’s still option 11.  You will have to login as apc/apc to see option 11, if you just press enter twice to get in, there is another menu without option 11. Once you chosed option 11, you no longer can connect with 19200 bps, it has to be 2400 bps. One way to get it back is to reset by push down perf button on ATS for 10 seconds, till the light off. Just read the instruction once chose option 11.  Note this reset won’t change configurations already made, also I don’t know what difference of this with the reset pin button on the front panel of the network management card. ","date":"2012-11-07","objectID":"/assign-ip-address-to-apc-ups-and-problems-of-serial-connection/:0:0","tags":["DataCenter","APC","H/W"],"title":"Assign IP address to APC UPS and problems of Serial Connection","uri":"/assign-ip-address-to-apc-ups-and-problems-of-serial-connection/"},{"categories":null,"content":"v\\:* {behavior:url(#default#VML);} o\\:* {behavior:url(#default#VML);} w\\:* {behavior:url(#default#VML);} .shape {behavior:url(#default#VML);} Normal 0 false false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} APC support will most likely ask you to do it. It didn't solve my problem, but it suppose to be better, and very easy to do. Here is an example for updating firmware of Automatic Transfer Switch AP7750.Login to APC.com, and search for ap7750 to get to the product page. Click on Software \u0026 Firmware tab, and download the following file. Run it. After extraction, one Dos prompt windows with the following command will pop up another DOS prompt. That will finish the upgrade.  During the update ATS will remain online, but the management interface will be offline temporarily. --  --  --  --   --  --  --  --   --  --  --  --   --  --  --  --   --  --  --  --  C:\\temp\u003estart /wait upgrd_util.exe--  --  --  --   --  --  --  --   --  --  --  --   --  --  --  --   --  --  --  --  NMC Upgrade Tool v1.5dWed Oct 24 12:16:32 AMAmerican Power Conversion               Network Management Card AOS    v2.6.4(c) Copyright 2004 All Rights Reserved  Automatic Transfer Switch APP  v2.6.1-----------------------------------------------------------------------------        *************************************************************        Warning: User name and password information will be displayed        to the screen in clear text.        *************************************************************        IP Address of target to upgrade: 10.10.10.10        User Name: apc        Password:apc        You have entered:        IP Address: 10.10.10.10        Username:   apc        Password:   apc        1: Continue with upgrade        2: Re-enter parameters        3: Quit        Action: 1        ***************************************************        Starting Upgrade to 10.10.10.10.        Checking network connection ...                  OK        Testing login ...                                OK        Saving log files                                 OK        Checking version information ...                 OK        Attempting to log in ...                         OK        Loading OS, please wait ...                      OK        Please wait (1 minute) for system updates        OK        Attempting connection to verify restart          OK        Attempting to log in ...                         OK        Loading application, please wait ...             OK        Please wait (3-4 minutes) for system update      OK        Attempting connection to verify restart          OK        *********** Upgrade Summary ***********        All upgrades completed successfully.        Warning: A file called 'iplist.txt' exists in this directory        that may contain user names and passwords in clear text.        You may want to delete this file if other users have access        to this directory.        Thank you for using APC products        Press \u003cEnter\u003e to exit. ","date":"2012-11-07","objectID":"/apc-ups-ats-firmware-update/:0:0","tags":["DataCenter","APC","H/W"],"title":"APC UPS / ATS firmware update","uri":"/apc-ups-ats-firmware-update/"},{"categories":null,"content":" Wipe devices and “Reset to factory default” won’t touch the plugged in media card，but it will remove any media files save in the built-in memory. This memory is getting bigger nowadays, it’s common to see media files here. I didn’t know there is such a different, and made mistakes. ","date":"2012-10-31","objectID":"/be-careful-about-the-built-in-media-card-for-bb-before-wipe-it./:0:0","tags":null,"title":"Be careful about the built-in media card for BB before wipe it. ","uri":"/be-careful-about-the-built-in-media-card-for-bb-before-wipe-it./"},{"categories":null,"content":" IT Polices normally have media card encrypted. After remove IT policy from Blackberry, the media card encryption is still enabled. That’s why you still have to use password. If user can’t remember media card password, they can’t disable it, then you can’t remove your password. While this sounds disappointing, but reasonable, there is a way out. Shutdown, take the media card out, boot it. Now you can use the new password you putted in after wiped the BB to disable media encryption, in turn you can disable the password. ","date":"2012-10-31","objectID":"/after-remove-it-policy-from-blackberry-still-cant-disable-password/:0:0","tags":null,"title":"After remove IT policy from Blackberry, still can't disable password?","uri":"/after-remove-it-policy-from-blackberry-still-cant-disable-password/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} Do this from the exchange server side:http://support.microsoft.com/kb/266166/en-usThen do this from outlook client side:http://support.microsoft.com/kb/291956 ","date":"2012-10-31","objectID":"/how-to-setup-an-automatic-reply-message-for-a-resume-inbox/:0:0","tags":null,"title":"How to setup an automatic reply message for a resume inbox ","uri":"/how-to-setup-an-automatic-reply-message-for-a-resume-inbox/"},{"categories":null,"content":" Normal 0 false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} To remove IT policy on your BB, don’t wipe, just reset to factory default. What is an IT Policy and how can I view it?My first mistake is, I thought \"Reset to factory default\" is more cleaner, but it’s not. My understanding is they are different thing. Here is statement from BlackBerry official tech support. The factory reset performs much like the Wipe Handheld option from the BlackBerry smartphone, with some minor differences. Wipe Handheld - The Wipe Handheld option is performed directly on the BlackBerry smartphone (see KB02318 and KB14058). This option removes all BlackBerry application data (emails, address book entries, calendar events, etc.), and allows the deletion of User Installed Applications and the content of the Media Card.Reset to Factory Defaults - Application data will be removed and so are IT Policies. Third-party programs will  NOT be affected by this operation. They will remain intact. My second mistake. Everybody knows this, the most of important thing here is to back up first. Since my BB has a big built-in memory, I don’t really have a media card, all my media files are saved there. I thought my Giga-bytes of media files will be bypassed, so my backup didn’t include build-in media card, that’s a big mistake. The wipe Handheld process deleted all of them, it affected my background picture, and ringtone. Restore will bring the list back, but not the actual files. The names are dimmed. BES Activation won’t bring previous emails you received back, it will make you receive new emails. Old emails still have to be restore from your backup. ","date":"2012-10-17","objectID":"/blackberry-reset-to-factory-default-or-wipe/:0:0","tags":null,"title":"Blackberry: reset to factory default or wipe ","uri":"/blackberry-reset-to-factory-default-or-wipe/"},{"categories":null,"content":"Note: you need Admin privilege to do things below.   Error Message : The terminal server has exceeded the maximum number of allowed connections. Cause: Normal server only allow 2 sessions of RDP. If someone didn’t log off properly, and left the server with a disconnected session, that session will stay there until it to be reset. Listing : Pay attention to session name and ID, they will be used to be terminated later on.  H:\u0026gt;qwinsta /server:server1 SESSIONNAME USERNAME ID STATE TYPE DEVICE console 0 Conn wdcon rdp-tcp 65536 Listen rdpwd rdp-tcp#25 admin1 5 Active rdpwd rdp-tcp#16 admin2 7 Active rdpwd Reseting: Command Sytax. Sometimes session name is not available, you can use session ID. RESET SESSION {sessionname | sessionid} [/SERVER:servername] [/V] sessionname Identifies the session with name sessionname. sessionid Identifies the session with ID sessionid. /SERVER:servername The server containing the session (default is current). /V Display additional information. H:\u0026gt;reset session rdp-tcp#16 /server:server1 /v Resetting session rdp-tcp#16 Session rdp-tcp#16 has been reset H:\u0026gt;reset session 5 /server:server1 /v Resetting session ID 5 Session ID 5 has been reset Shadowing: Mstsc.exe [/shadow:sessionID [/v:Servername] [/control] [/noConsentPrompt]]  For example: mstsc /shadow:5 /v:server1 /control /noConsentPrompt Note: noconsentPrompt might be blocked by GPO. Another way to reset: RDP to a server which is a Terminal Server,(Terminal Server can be installed by “Manage Your Server -\u003e Server Role”) start the\"Terminal Services Manger” and connect to the first server. From there you can reset a session. ","date":"2012-10-16","objectID":"/list-and-reset-or-shaow-rdp-sessions/:0:0","tags":null,"title":"List and reset or Shaow RDP sessions ","uri":"/list-and-reset-or-shaow-rdp-sessions/"},{"categories":null,"content":"Installed it successful with following environment: Virtualbox 4.2.0 on Windows 7 9200.16384.WIN8_RTM.120725-1247_X64FRE_SERVER_EVAL_EN-US-HRM_SSS_X64FREE_EN-US_DV5.ISO ","date":"2012-10-16","objectID":"/install-windows-server-2012-on-virtualbox/:0:0","tags":null,"title":"Install Windows Server 2012 on VirtualBox","uri":"/install-windows-server-2012-on-virtualbox/"},{"categories":null,"content":"It looks like this Here is how to solve this problem. ","date":"2012-10-11","objectID":"/pdf-cant-been-displayed-in-browser/:0:0","tags":null,"title":"PDF can't been displayed in Browser","uri":"/pdf-cant-been-displayed-in-browser/"},{"categories":null,"content":"The left is original file, and the right is after convert with BB desktop software. The size has changed, but it doesn’t guarantee the file size on BB will be smaller. The file will be convert to MP4 format, and it’s much bigger than WMA for some video files. Normal 0 false false false false EN-US ZH-CN X-NONE MicrosoftInternetExplorer4 /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:\"Times New Roman\"; mso-bidi-theme-font:minor-bidi;} ","date":"2012-10-11","objectID":"/compair-the-vedio-files-converted-by-blackberry-desktop-software/:0:0","tags":null,"title":"Compair the vedio files converted by BlackBerry Desktop Software","uri":"/compair-the-vedio-files-converted-by-blackberry-desktop-software/"},{"categories":null,"content":"Refer to Zenapp for original post. I have added a little bit myself. IEESC (IE Enhanced Security Mode) is a very good feature on most servers – you shouldn’t be doing much web surfing from your server’s desktop anyway and this helps protect you from malware, which is the last thing you want on a Windows Server system. Of course if Microsoft had any guts IE would be disabled by default, but I digress. Is it on or off? The obvious way is to start IE, and your home page is set to res://shdoclc.dll/hardAdmin.htm, which shows you it’s enabled. This is not accurate because I can manually set my home page to this address, and it will shows it’s Enabled, even it’s NOT. As shown in the following picture. Turning off IE ESC Manually On Windows 2003 Server it was easy – just open up Add/Remove Programs and remove the component from the server – IE becomes fully opened up. Windows Server 2008 and 2008 R2 had a nice easy way to do this as well. Just load up Server Manager (you know, that annoying screen that pops up every time you log in… okay, its in Administrative Tools if you have never used a computer before). Use servermanager.msc command to bring it up if you don’t have it opened. About a third down, see the Configure IE ESC link. Click it and you should see this box – by default a XenApp 6 server will have IE ESC turned off the users (cleverly) but on for administrators (annoyingly, especially if you are an administrator and you actually use Citrix). Configure as you see fit – personally its Off for both for me on all Citrix servers. ","date":"2012-08-30","objectID":"/ie-enhanced-security-mode-and-turning-it-off/:0:0","tags":null,"title":"IE Enhanced Security Mode and Turning it off","uri":"/ie-enhanced-security-mode-and-turning-it-off/"},{"categories":null,"content":"Symptoms:Error explained by LockLizard Error Message: Please close your capture application and press ok to continue (capture.exe)Posted by LockLizard Support on 21 November 2011 04:12 PMThis message is displayed if you have an application running which ends in capture.exe (e.g. screencapture.exe, m4capture.exe, wincapture.exe). You need to close down any processes that end in capture.exe by pressing CTRL-ALT-DEL on your keyboard, then Task Manager \u003e Processes. If you want to check what processes are running, follow the steps below: 1. Open command prompt with admin rights. That is, type in cmd either in Start menu search box and hit Ctrl + Shift +Enter. 2. Click continue if you get the User Account Control (UAC) Prompt. 3. Here, first type the command tasklist and hit enter to see the list of running processes. 4. If you can see the running processes then type another command tasklist\u003ec:\\list.txt which gives you the output as list.txt file in \"c\" drive. Note that you can change the drive letter \"c\" and also the output file name (list.txt). 5. Type exit and go back to your \"C\" drive were your copy is available.  You can also Type tasklist/svc\u003ec:\\processlist.txt to also get a list of services running. SolutionC:\\\u003etasklist | find \"Capture\" uArcCapture.exe               3504 Services                   0      1,680 K C:\\\u003esc query uArcCapture SERVICE_NAME: uArcCapture         TYPE               : 10  WIN32_OWN_PROCESS         STATE              : 4  RUNNING                                 (STOPPABLE, NOT_PAUSABLE, IGNORES_SHUTDOWN)         WIN32_EXIT_CODE    : 0  (0x0)         SERVICE_EXIT_CODE  : 0  (0x0)         CHECKPOINT         : 0x0         WAIT_HINT          : 0x0 ","date":"2012-08-27","objectID":"/cant-open-file-with-locklizard/:0:0","tags":null,"title":"Can't open file with LockLizard","uri":"/cant-open-file-with-locklizard/"}]